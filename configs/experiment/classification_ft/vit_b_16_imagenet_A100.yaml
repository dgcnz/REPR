# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: im1k
  - override /model: classification_ft/vit_b_16_224
  - override /callbacks:
    - loggers/classification_ft/metric_logger
    - lr_monitor
  - override /trainer: ddp
  - override /logger: wandb


tags: ["classification_ft"]

seed: 12345
float32_matmul_precision: "high"

trainer:
  min_epochs: 15
  max_epochs: 200
  check_val_every_n_epoch: 1
  deterministic: true
  devices: 4
  num_nodes: 1
  sync_bachnorm: true
  strategy:
    _target_: src.strategies.ddp_compile.DDPCompileStrategy

model:
  num_classes: 1000
  optimizer:
    lr: 1e-4
  scheduler:
    warmup_t: 5
  scheduler_interval: epoch

  net:
    pretrained_cfg_overlay:
      file:
        module_ckpt_path: "logs/train/runs/2025-01-26_23-51-51/PARTv2/ukjrb3lq/checkpoints/epoch\=41-step\=52584.ckpt"

data:
  batch_size: 1024
  num_workers: 16
  test_fraction: 0.2
  cache_dir: /scratch-shared/dcanez/HF_HOME

logger:
  wandb:
    project: "PARTv2-classification-ft"
    group: "vit_b_16_imagenet_A100"


