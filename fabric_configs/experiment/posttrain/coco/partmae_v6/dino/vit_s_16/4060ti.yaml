# @package _global_
defaults:
  - posttrain/coco/partmae_v6/dino/vit_s_16/_base

compile: False

total_batch_size: 512
ckpt_path: artifacts/dino_deitsmall16_pretrain_full_checkpoint.pth

# blr: 5e-6
blr: 5e-7

trainer:
  max_epochs: 100
  accelerator: gpu

model:
  lambda_pmatch: 0
  lambda_pcr: 0
  lambda_ccr: 0.05
  lambda_cinv: 0.05
  lambda_pose: 0.9
  decoder_embed_dim: 256
  decoder_from_proj: true
  decoder_depth: 2

callbacks:
  checkpoint:
    save_perm_every_n_steps: 1000
    save_temp_every_n_steps: 100
  metric_logger:
    every_n_steps: 10
  iter_timer:
    every_n_steps: 10

scheduler:
  warmup_t: ${eval:10 * ${steps_per_epoch}} # 10 epochs
  t_initial: ${eval:${trainer.max_epochs} * ${steps_per_epoch}} # 100 epochs

data:
  root: /mnt/sdb1/datasets/coco/train2017

train_dataloader:
  batch_size: 256
  num_workers: 8

# evals:
#   - name: hummingbird
#     fn:
#       _target_: src.experiments.engine_hummingbird.eval
#       cfg:
#         model: partmae_v6
#         data: voc-mini
#         model.pretrained_cfg_overlay.state_dict.state_dict.f: ${paths.output_dir}/last.ckpt
