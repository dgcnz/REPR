# @package _global_
defaults:
  - pretrain/in1k/partmae_v6/vit_b_16/_base
  - override /data: in1k_snellius

compile: False

total_batch_size: 1024

trainer:
  max_epochs: 200
  accelerator: gpu
  strategy: ddp
  num_nodes: 1
  devices: 4

warmup_epochs: 10
scheduler:
  # 625 steps per epoch when effective batch size is 2048
  warmup_t: ${eval:{warmup_epochs} * ${steps_per_epoch}} # 10 epochs * 625 steps/epoch
  t_initial: ${eval:{trainer.max_epochs} * ${steps_per_epoch}} # 200 epochs * 625 steps/epoch

train_dataloader:
  batch_size: 256
  num_workers: 16
