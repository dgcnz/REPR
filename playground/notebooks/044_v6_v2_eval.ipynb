{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from src.models.components.partmae_v6 import PARTMaskedAutoEncoderViT\n",
    "from src.data.components.transforms.multi_crop_v4 import ParametrizedMultiCropV4\n",
    "from lightning import Fabric\n",
    "from tqdm import tqdm\n",
    "from torch import nn, Tensor\n",
    "import torch\n",
    "from torch.utils.data import  default_collate\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils._pytree as pytree\n",
    "# from src.utils.visualization.reconstruction_v5_anchor_reparam import reconstruction_lstsq_with_anchor_reparam\n",
    "from src.utils.visualization.reconstruction_v6 import reconstruction_lstsq_with_anchor_reparam\n",
    "from src.utils.visualization.reconstruction_v5_gt import reconstruction_gt\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_model_io(batch: tuple, out: dict, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Clean and organize model inputs and outputs for visualization and analysis.\n",
    "    \n",
    "    Args:\n",
    "        batch: A tuple containing model inputs (global images, global params, local images, local params)\n",
    "        out: Model output dictionary\n",
    "        device: Device to move tensors to (default: \"cuda\")\n",
    "        \n",
    "    Returns:\n",
    "        io: Dictionary containing organized model inputs and outputs\n",
    "    \"\"\"\n",
    "    # Initialize output dictionary\n",
    "    io = dict()\n",
    "    \n",
    "    # Extract shapes from model output\n",
    "    io[\"x\"] = [list(itertools.chain.from_iterable(items)) for items in zip(*batch[0])]\n",
    "    io[\"params\"] = [list(itertools.chain.from_iterable(items)) for items in zip(*batch[1])]\n",
    "    io[\"canonical_params\"] = [[param[0:4] for param in batch_params] for batch_params in io[\"params\"]][0]\n",
    "    io[\"crop_params\"] = [[param[4:8] for param in batch_params] for batch_params in io[\"params\"]]\n",
    "    \n",
    "    # Include all output values\n",
    "    io.update({name: out[name] for name in out.keys()})\n",
    "    \n",
    "    # Move all tensors to the specified device\n",
    "    io = pytree.tree_map_only(\n",
    "        Tensor,\n",
    "        lambda t: t.detach().to(device),\n",
    "        io\n",
    "    )\n",
    "    return io\n",
    "\n",
    "\n",
    "def make_plots(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    original_img,\n",
    "):\n",
    "    \n",
    "    gt_reconstruction = reconstruction_gt(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "    )\n",
    "    pred_reconstruction, *_ = reconstruction_lstsq_with_anchor_reparam(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "        max_scale_ratio=model.max_scale_ratio,\n",
    "        pred_dT=io[\"pred_dT\"][0],\n",
    "    )\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    canonical_img = train_transform.recreate_canonical(\n",
    "        original_img, io[\"canonical_params\"][0]\n",
    "    )\n",
    "    axes[0].imshow(canonical_img)\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(gt_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[1].set_title(\"GT Reconstruction\")\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[2].imshow(pred_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[2].set_title(\"Reconstruction\")\n",
    "    axes[2].axis(\"off\")\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit to a few batches\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../../\")\n",
    "if not OmegaConf.has_resolver(\"eval\"):\n",
    "    OmegaConf.register_new_resolver(\"eval\", eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDER = ROOT / Path(\"outputs/2025-06-16/13-23-31\")\n",
    "FOLDER = ROOT / Path(\"outputs/2025-06-22/19-16-53\")\n",
    "cfg = OmegaConf.load(FOLDER / \".hydra/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(FOLDER / \".hydra/config.yaml\")\n",
    "if \"predict_uncertainty\" in cfg[\"model\"]:\n",
    "    predict_uncertainty = cfg[\"model\"].pop(\"predict_uncertainty\")\n",
    "    if predict_uncertainty:\n",
    "        cfg[\"model\"][\"uncertainty_mode\"] = \"additive\"\n",
    "    else:\n",
    "        cfg[\"model\"][\"uncertainty_mode\"] = \"none\"\n",
    "elif \"uncertainty_mode\" in cfg[\"model\"]:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(\"Uncertainty mode not specified in the config.\")\n",
    "print(cfg[\"model\"][\"uncertainty_mode\"])\n",
    "ckpt_path = FOLDER / \"epoch_0199.ckpt\"\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cuda\")\n",
    "state_dict = ckpt[\"model\"]\n",
    "if \"pose_head.mu.weight\" in state_dict:\n",
    "    state_dict[\"pose_head.mu_proj.weight\"] = state_dict.pop(\"pose_head.mu.weight\")\n",
    "if \"pose_head.logvar.weight\" in state_dict:\n",
    "    state_dict[\"pose_head.disp_proj.weight\"] = state_dict.pop(\"pose_head.logvar.weight\")\n",
    "if \"pose_head.logvar.bias\" in state_dict:\n",
    "    state_dict[\"pose_head.disp_proj.bias\"] = state_dict.pop(\"pose_head.logvar.bias\")\n",
    "if \"pose_head.gate_proj.weight\" in state_dict:\n",
    "    if \"gate_dim\" not in cfg[\"model\"]:\n",
    "        cfg[\"model\"][\"gate_dim\"] = state_dict[\"pose_head.gate_proj.weight\"].shape[0]\n",
    "        print(f\"Gate dimension not specified in the config, inferring from state_dict: {cfg['model']['gate_dim']}\")\n",
    "    assert cfg[\"model\"][\"gate_dim\"] == state_dict[\"pose_head.gate_proj.weight\"].shape[0]\n",
    "if \"pose_head.gate_mult\" not in state_dict:\n",
    "    state_dict[\"pose_head.gate_mult\"] = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 2\n",
    "gV = 2\n",
    "lV = V - gV\n",
    "if V == 12:\n",
    "    model = hydra.utils.instantiate(\n",
    "        cfg[\"model\"],\n",
    "        # gate_dim=cfg[\"model\"].get(\"gate_dim\", 16),\n",
    "        _target_=\"src.models.components.partmae_v6.PARTMaskedAutoEncoderViT\",\n",
    "        num_views=V,\n",
    "        # mask_ratio=0,\n",
    "        mask_ratio=0.75,\n",
    "        pos_mask_ratio=0.75,\n",
    "        # sampler='ongrid_canonical'\n",
    "    )\n",
    "elif V == 2:\n",
    "    model = hydra.utils.instantiate(\n",
    "        cfg[\"model\"],\n",
    "        # gate_dim=cfg[\"model\"].get(\"gate_dim\", 16),\n",
    "        _target_=\"src.models.components.partmae_v6.PARTMaskedAutoEncoderViT\",\n",
    "        num_views=V,\n",
    "        mask_ratio=0,\n",
    "        pos_mask_ratio=0.75,\n",
    "        # sampler='ongrid_canonical'\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported number of views: {V}\")\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "print(ckpt[\"global_step\"], ckpt[\"epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"../../artifacts/dog.jpg\")\n",
    "# .crop((0, 0, 1000, 1000))\n",
    "train_transform = hydra.utils.instantiate(\n",
    "    cfg[\"data\"][\"transform\"], distort_color=False, n_local_crops=V - gV\n",
    ")\n",
    "batch = default_collate([train_transform(img), train_transform(img), train_transform(img), train_transform(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytree.tree_map_only(Tensor, lambda t: t.shape, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(*batch)\n",
    "io = clean_model_io(batch, out, 'cuda')\n",
    "fig, axes = make_plots(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def paste_patch(\n",
    "    crop: Float[Tensor, \"C h w\"],\n",
    "    pos: Float[Tensor, \"2\"],\n",
    "    pos_canonical: Float[Tensor, \"2\"],\n",
    "    patch_size_canonical: Float[Tensor, \"2\"],\n",
    "    canvas: Float[Tensor, \"C H W\"],\n",
    "    count_map: Float[Tensor, \"1 H W\"],\n",
    "    patch_size: int,\n",
    "    canonical_size: int,\n",
    "    disp: Float[Tensor, \"4\"] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract a patch from a crop at pos and paste it onto a canvas at pos_canonical with appropriate rescaling.\n",
    "\n",
    "    Args:\n",
    "        crop: Source image crop of shape [C, h, w]\n",
    "        pos: Patch position in crop coordinates [y, x]\n",
    "        pos_canonical: Target position in canonical coordinates [y, x]\n",
    "        patch_size_canonical: Size of patch in canonical space [height, width]\n",
    "        canvas: Target canvas to paste onto [C, H, W]\n",
    "        count_map: Counter for averaging overlapping patches [1, H, W]\n",
    "        patch_size: Size of patch in crop space\n",
    "        canonical_size: Size of the canonical image\n",
    "        disp: Per token dispersion (as in Laplace scale) for each transformation parameter.\n",
    "\n",
    "        pos ~ Laplace(mu_yx, b_yx) \n",
    "    \"\"\"\n",
    "    crop_h, crop_w = crop.shape[1:3]\n",
    "\n",
    "    # Convert to integer coordinates for the canonical position\n",
    "    y_canonical, x_canonical = int(round(pos_canonical[0].item())), int(\n",
    "        round(pos_canonical[1].item())\n",
    "    )\n",
    "\n",
    "    # Get integer patch size for the canonical space\n",
    "    patch_h_canonical, patch_w_canonical = patch_size_canonical.round().int()\n",
    "\n",
    "    # Ensure the patch fits within the canonical canvas\n",
    "    y_canonical = max(0, min(canonical_size - patch_h_canonical, y_canonical))\n",
    "    x_canonical = max(0, min(canonical_size - patch_w_canonical, x_canonical))\n",
    "\n",
    "    # Get source patch coordinates, ensuring they're within the crop boundaries\n",
    "    y_crop, x_crop = int(round(pos[0].item())), int(round(pos[1].item()))\n",
    "    y_crop = max(0, min(crop_h - patch_size, y_crop))\n",
    "    x_crop = max(0, min(crop_w - patch_size, x_crop))\n",
    "\n",
    "    # Extract the patch from the source crop\n",
    "    patch = crop[\n",
    "        :, y_crop : y_crop + patch_size, x_crop : x_crop + patch_size\n",
    "    ].unsqueeze(0)\n",
    "\n",
    "    # Resize the patch to the canonical size\n",
    "    patch_resized = F.interpolate(\n",
    "        patch,\n",
    "        size=(patch_h_canonical, patch_w_canonical),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).squeeze(0)\n",
    "\n",
    "    # Add the patch to the canvas and update the count map\n",
    "    canvas[\n",
    "        :,\n",
    "        y_canonical : y_canonical + patch_h_canonical,\n",
    "        x_canonical : x_canonical + patch_w_canonical,\n",
    "    ] += patch_resized\n",
    "    count_map[\n",
    "        :,\n",
    "        y_canonical : y_canonical + patch_h_canonical,\n",
    "        x_canonical : x_canonical + patch_w_canonical,\n",
    "    ] += 1\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def reconstruction_with_uncertainty_visualization(\n",
    "    x: list[Float[Tensor, \"C gH gW\"] | Float[Tensor, \"C lH lW\"]],\n",
    "    patch_positions_nopos: Float[Tensor, \"M 2\"],\n",
    "    num_tokens: list[int],\n",
    "    crop_params: list[Float[Tensor, \"4\"]],\n",
    "    patch_size: int,\n",
    "    canonical_img_size: int,\n",
    "    max_scale_ratio: float,\n",
    "    pred_dT: Float[Tensor, \"M M 4\"],\n",
    "    disp_T: Float[Tensor, \"M 4\"],  # NOTE: This contains LOG-dispersions\n",
    "    uncertainty_mode: Literal[\"none\", \"global_heatmap\", \"laplace_distributions\"] = \"none\",\n",
    ") -> tuple[\n",
    "    Float[Tensor, \"C canonical_img_size canonical_img_size\"],  # reconstructed image\n",
    "    Float[Tensor, \"canonical_img_size canonical_img_size\"] | None,  # uncertainty map\n",
    "]:\n",
    "    \"\"\"\n",
    "    Reconstruct image with optional uncertainty visualization.\n",
    "    \n",
    "    Args:\n",
    "        disp_T: Per-token log-dispersions [M, 4] - NOTE: these are in log-space!\n",
    "        uncertainty_mode: \n",
    "            - \"none\": No uncertainty visualization\n",
    "            - \"global_heatmap\": Global uncertainty heatmap using dispersion norms\n",
    "            - \"laplace_distributions\": Individual Laplace distribution heatmaps\n",
    "    \n",
    "    Returns:\n",
    "        reconstructed_img: Reconstructed canonical image\n",
    "        uncertainty_map: Uncertainty visualization (None if uncertainty_mode=\"none\")\n",
    "    \"\"\"\n",
    "    device = x[0].device\n",
    "    C = x[0].shape[0]\n",
    "\n",
    "    # Undo normalization\n",
    "    dT = pred_dT[..., :2] * canonical_img_size\n",
    "    dS = pred_dT[..., 2:] * math.log(max_scale_ratio)\n",
    "\n",
    "    # Choose anchor\n",
    "    T_anchor = (\n",
    "        crop_params[0][:2]\n",
    "        + (patch_positions_nopos[0] / x[0].shape[1]) * crop_params[0][2:4]\n",
    "    )\n",
    "    S_anchor = torch.log((patch_size * crop_params[0][2:4] / x[0].shape[1]))\n",
    "\n",
    "    T_global = dT[:, 0] + T_anchor\n",
    "    S_global = dS[:, 0] + S_anchor\n",
    "\n",
    "    T_global_grouped = torch.split(T_global, num_tokens)\n",
    "    S_global_grouped = torch.split(S_global, num_tokens)\n",
    "    patch_positions_nopos_grouped = torch.split(patch_positions_nopos, num_tokens)\n",
    "    disp_T_grouped = torch.split(disp_T, num_tokens)\n",
    "\n",
    "    # Reconstruct the canonical image\n",
    "    canvas = torch.zeros((C, canonical_img_size, canonical_img_size), device=device)\n",
    "    count_map = torch.zeros((1, canonical_img_size, canonical_img_size), device=device)\n",
    "\n",
    "    for crop, patch_positions, canonical_pos, log_size, disp in zip(\n",
    "        x,\n",
    "        patch_positions_nopos_grouped,\n",
    "        T_global_grouped,\n",
    "        S_global_grouped,\n",
    "        disp_T_grouped,\n",
    "    ):\n",
    "        N = patch_positions.shape[0]\n",
    "        for i in range(N):\n",
    "            paste_patch(\n",
    "                crop=crop,\n",
    "                pos=patch_positions[i].float(),\n",
    "                pos_canonical=canonical_pos[i],\n",
    "                patch_size_canonical=torch.exp(log_size[i]),\n",
    "                canvas=canvas,\n",
    "                count_map=count_map,\n",
    "                patch_size=patch_size,\n",
    "                canonical_size=canonical_img_size,\n",
    "                disp=disp[i]\n",
    "            )\n",
    "\n",
    "    count_map[count_map == 0] = 1\n",
    "    reconstructed_img = canvas / count_map\n",
    "\n",
    "    # Generate uncertainty visualization\n",
    "    uncertainty_map = None\n",
    "    if uncertainty_mode != \"none\":\n",
    "        # Convert log-dispersions to actual dispersions and scale to pixel units\n",
    "        # disp_T contains log-dispersions, so we need to exp() them first\n",
    "        actual_dispersions = torch.exp(disp_T)  # Convert from log-space\n",
    "        disp_T_pixels = actual_dispersions.clone()\n",
    "        disp_T_pixels[:, :2] *= canonical_img_size  # dy, dx to pixels\n",
    "        disp_T_pixels[:, 2:] *= math.log(max_scale_ratio)  # log-scale factors\n",
    "        \n",
    "        if uncertainty_mode == \"global_heatmap\":\n",
    "            uncertainty_map = create_global_uncertainty_heatmap(\n",
    "                T_global, disp_T_pixels, canonical_img_size, patch_size\n",
    "            )\n",
    "        elif uncertainty_mode == \"laplace_distributions\":\n",
    "            uncertainty_map = create_laplace_distribution_heatmaps(\n",
    "                T_global, disp_T_pixels, canonical_img_size, patch_size\n",
    "            )\n",
    "\n",
    "    return reconstructed_img, uncertainty_map\n",
    "\n",
    "\n",
    "def plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    original_img,\n",
    "    uncertainty_mode: Literal[\"none\", \"global_heatmap\", \"laplace_distributions\"] = \"none\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Updated plotting function that supports uncertainty visualization.\n",
    "    \"\"\"\n",
    "    # Generate GT reconstruction (unchanged)\n",
    "    gt_reconstruction = reconstruction_gt(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "    )\n",
    "    \n",
    "    # Generate prediction with uncertainty\n",
    "    pred_reconstruction, uncertainty_map = reconstruction_with_uncertainty_visualization(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "        max_scale_ratio=model.max_scale_ratio,\n",
    "        pred_dT=io[\"pred_dT\"][0],\n",
    "        disp_T=io[\"disp_T\"][0],\n",
    "        uncertainty_mode=uncertainty_mode,\n",
    "    )\n",
    "    \n",
    "    # Determine number of subplots\n",
    "    n_plots = 4 if uncertainty_mode != \"none\" else 3\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(4*n_plots, 4))\n",
    "    \n",
    "    # Original image\n",
    "    canonical_img = train_transform.recreate_canonical(\n",
    "        original_img, io[\"canonical_params\"][0]\n",
    "    )\n",
    "    axes[0].imshow(canonical_img)\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # GT reconstruction\n",
    "    axes[1].imshow(gt_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[1].set_title(\"GT Reconstruction\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    # Predicted reconstruction\n",
    "    axes[2].imshow(pred_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[2].set_title(\"Reconstruction\")\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    # Uncertainty visualization\n",
    "    if uncertainty_mode != \"none\" and uncertainty_map is not None:\n",
    "        im = axes[3].imshow(uncertainty_map.cpu(), cmap='hot', alpha=0.8)\n",
    "        axes[3].set_title(f\"Uncertainty ({uncertainty_mode})\")\n",
    "        axes[3].axis(\"off\")\n",
    "        plt.colorbar(im, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(io[\"disp_T\"].shape) # [1, 294, 4] # [B, M, 4] # 4 for dy, dx, dlogh, dlogw\n",
    "print(io[\"patch_positions_nopos\"].shape) # [1, 294, 2] # y, x coordinates, where \n",
    "print(io[\"gt_dT\"].shape) # [1, 294, 4] # ground truth displacement\n",
    "# each disp_T is associated with a patch position, where \n",
    "print(io[\"patch_positions_nopos\"].max())\n",
    "print(io[\"params\"])\n",
    "print(io[\"crop_params\"])\n",
    "# the way to get the coordinates of each patch in the canonical image is to first obtain an anchor\n",
    "# that is, let's pick patch 0, obtain its position in the canonical image and then add it to gt_dT\n",
    "\n",
    "\"\"\"\n",
    "dT = pred_dT[..., :2] * canonical_img_size\n",
    "dS = pred_dT[..., 2:] * math.log(max_scale_ratio)\n",
    "\n",
    "\n",
    "# Choose the anchor: first patch of the first global crop (global index 0).\n",
    "T_anchor = (\n",
    "    crop_params[0][:2]\n",
    "    + (patch_positions_nopos[0] / x[0].shape[1]) * crop_params[0][2:4]\n",
    ")\n",
    "S_anchor = torch.log((patch_size * crop_params[0][2:4] / x[0].shape[1]))\n",
    "\n",
    "T_global = dT[:, 0] + T_anchor\n",
    "S_global = dS[:, 0] + S_anchor\n",
    "\"\"\"\n",
    "\n",
    "batch_idx = 0\n",
    "anchor_idx = 0\n",
    "crop_size = io[\"x\"][batch_idx][0].shape[-1]\n",
    "\n",
    "anchor_params = io[\"crop_params\"][batch_idx][anchor_idx]\n",
    "anchor_local_pos = io[\"patch_positions_nopos\"][batch_idx][anchor_idx]\n",
    "anchor_global_pos = anchor_params[:2] + (anchor_local_pos / crop_size) * anchor_params[2:4]\n",
    "anchor_global_scale = torch.log((model.patch_size * anchor_params[2:4] / crop_size))\n",
    "print(\"Anchor global position:\", anchor_global_pos)\n",
    "print(\"Anchor global scale:\", anchor_global_scale)\n",
    "\n",
    "# Calculate global positions and scales for all patches\n",
    "gt_dt = io[\"gt_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "gt_ds = io[\"gt_dT\"][batch_idx, :, :, 2:] * math.log(model.max_scale_ratio)\n",
    "pred_dt = io[\"pred_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "pred_ds = io[\"pred_dT\"][batch_idx, :, :, 2:] * math.log(model.max_scale_ratio)\n",
    "\n",
    "print(io[\"gt_dT\"].shape)  # [1, 294, 294, 4]\n",
    "print(gt_dt.shape)  # [294, 2]\n",
    "print(anchor_global_pos.shape)  # [2]\n",
    "# gt_T_global and gt_S_global are the global positions and scales for all patches\n",
    "gt_T_global = gt_dt[:, 0] + anchor_global_pos\n",
    "gt_S_global = gt_ds[:, 0] + anchor_global_scale\n",
    "# pred_T_global and pred_S_global are the predicted means of the global positions and scales for all patches\n",
    "pred_T_global = pred_dt[:, 0] + anchor_global_pos\n",
    "pred_S_global = pred_ds[:, 0] + anchor_global_scale\n",
    "\n",
    "print(\"Global positions:\", gt_T_global.shape)\n",
    "print(\"Global scales:\", gt_S_global.shape)\n",
    "\n",
    "# cool\n",
    "# now, let's pick an arbitrary patch\n",
    "# and plot a laplacian distribution of the displacements given the mean (pred_dT) and the variance/lap. scale (disp_dT)\n",
    "\n",
    "patch_idx = 0\n",
    "print(io[\"disp_dT\"].shape)  # [1, 294, 294, 4]\n",
    "disp_patch_to_all = io[\"disp_dT\"][batch_idx, patch_idx]\n",
    "# we can only visualize the y and x dispersions\n",
    "disp_patch_to_all = disp_patch_to_all[:, :2]  # [294, 2]\n",
    "\n",
    "print(pred_T_global.shape)\n",
    "mu_patch = pred_T_global[patch_idx]  # [2]\n",
    "\n",
    "# now, we display the canonical image\n",
    "canonical_img = train_transform.recreate_canonical(\n",
    "    img, io[\"canonical_params\"][0]\n",
    ")\n",
    "# and add a bounding box around the chosen patch_idx\n",
    "# and the laplacian distribution given the mean and the variance  (i assume as a heatmap)\n",
    "print(disp_patch_to_all.median())  # [294, 2]\n",
    "print(disp_patch_to_all.quantile(0.75) - disp_patch_to_all.quantile(0.25))  # [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the per-token dispersions.\n",
    "print(io[\"disp_T\"].shape) # (B, V * num_tokens_per_view, 4) # one uncertainty per dimension (y, x, dlogh, dlogw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "def visualize_patch_distribution(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx: int,\n",
    "    anchor_idx: int,\n",
    "    patch_idx: int,\n",
    "    figsize=(6,6),\n",
    "    disp_scale_pixels: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize the predicted 2D Laplacian distribution from anchor -> patch,\n",
    "    drawing ground-truth bounding boxes (top-left) for both anchor and target patches,\n",
    "    and displaying their exact positions in the legend.\n",
    "\n",
    "    Args:\n",
    "        io: dict with keys 'pred_dT','disp_dT','gt_dT','crop_params',\n",
    "            'patch_positions_nopos','canonical_params','x'\n",
    "        model: object with .canonical_img_size, .max_scale_ratio, .patch_size\n",
    "        train_transform: has .recreate_canonical(img, canonical_params)\n",
    "        img: input image for reconstruction\n",
    "        batch_idx: index into batch\n",
    "        anchor_idx: index of anchor patch/crop\n",
    "        patch_idx:  index of target patch\n",
    "        figsize:    matplotlib figure size\n",
    "        disp_scale_pixels: scale predicted dispersion to pixel units\n",
    "    \"\"\"\n",
    "    # sizes\n",
    "    anchor_view_idx = model.view_ids_M[anchor_idx]\n",
    "    anchor_crop_size = model.Is[anchor_view_idx]\n",
    "    canon_size = model.canonical_img_size\n",
    "    p_size = model.patch_size\n",
    "\n",
    "    # retrieve crop params and local positions\n",
    "    cp = io['crop_params'][batch_idx][anchor_view_idx]         # [y0,x0,h',w']\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]  # [y_loc, x_loc]\n",
    "\n",
    "    # anchor base top-left in global coords\n",
    "    anchor_tl = cp[:2] + (lp / anchor_crop_size) * cp[2:4]\n",
    "    ay_tl, ax_tl = anchor_tl.tolist()\n",
    "\n",
    "    # patch size in global coords\n",
    "    box_h, box_w = (p_size * cp[2:4] / anchor_crop_size).tolist()\n",
    "\n",
    "    # current patch TL\n",
    "    # py_tl = tls_y[patch_idx]\n",
    "    # px_tl = tls_x[patch_idx]\n",
    "    py_tl = anchor_tl[0].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 0].item() * canon_size\n",
    "    px_tl = anchor_tl[1].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 1].item() * canon_size\n",
    "\n",
    "    # predicted dispersion for heatmap\n",
    "    disp = io['disp_dT'][batch_idx, anchor_idx, :, :2]  # [N,2]\n",
    "    b_norm_y, b_norm_x = disp[patch_idx].cpu().tolist()\n",
    "    if disp_scale_pixels:\n",
    "        b_y = b_norm_y * canon_size\n",
    "        b_x = b_norm_x * canon_size\n",
    "    else:\n",
    "        b_y, b_x = b_norm_y, b_norm_x\n",
    "\n",
    "    # predicted mean offset for this patch\n",
    "    pred_off = io['pred_dT'][batch_idx, anchor_idx, patch_idx, :2] * canon_size\n",
    "    mu_y = (anchor_tl[0] - pred_off[0]).item()\n",
    "    mu_x = (anchor_tl[1] - pred_off[1]).item()\n",
    "\n",
    "    # reconstruct canonical image\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # build heatmap at predicted mean\n",
    "    ys = np.arange(H)[:,None]\n",
    "    xs = np.arange(W)[None,:]\n",
    "    Z = (1.0/(4*b_y*b_x)) * np.exp(-np.abs(ys-mu_y)/b_y - np.abs(xs-mu_x)/b_x)\n",
    "    # Z = Z / Z.max()\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(canon, interpolation='nearest')\n",
    "\n",
    "    # draw GT box for anchor (blue) at its top-left, with position in label\n",
    "    rect_a = Rectangle(\n",
    "        (ax_tl, ay_tl), box_w, box_h,\n",
    "        edgecolor='blue', lw=2, facecolor='none',\n",
    "        label=f'Anchor GT (TL): ({ay_tl:.1f}, {ax_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_a)\n",
    "\n",
    "    # draw GT box for target patch (red) at its top-left, with position\n",
    "    rect_p = Rectangle(\n",
    "        (px_tl, py_tl), box_w, box_h,\n",
    "        edgecolor='red', lw=2, facecolor='none',\n",
    "        label=f'Patch GT (TL): ({py_tl:.1f}, {px_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_p)\n",
    "\n",
    "    # overlay predicted Laplace heatmap\n",
    "    ax.imshow(Z, cmap='hot', alpha=0.5, extent=(0,W,H,0))\n",
    "\n",
    "    # legend and title\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(\n",
    "        f'anchor={anchor_idx} → patch={patch_idx}   '\\\n",
    "        f'Pred mean=(%.1f,%.1f)' % (mu_y, mu_x)\n",
    "    )\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "def visualize_patch_distribution_per_token(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx: int,\n",
    "    figsize=(6,6),\n",
    "    disp_scale_pixels: bool = True,\n",
    "):\n",
    "    #### 1. COMPUTE AN ANCHOR'S CANONICAL POSITION AND SIZE\n",
    "    # sizes\n",
    "    anchor_idx = 0 # this is just to make the predictions absolute\n",
    "    anchor_view_idx = model.view_ids_M[anchor_idx]\n",
    "    anchor_crop_size = model.Is[anchor_view_idx]\n",
    "    canon_size = model.canonical_img_size\n",
    "    p_size = model.patch_size\n",
    "\n",
    "    # retrieve crop params and local positions\n",
    "    cp = io['crop_params'][batch_idx][anchor_view_idx]         # [y0,x0,h',w']\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]  # [y_loc, x_loc]\n",
    "\n",
    "    # anchor base top-left in global coords\n",
    "    anchor_tl = cp[:2] + (lp / anchor_crop_size) * cp[2:4]\n",
    "    ay_tl, ax_tl = anchor_tl.tolist()\n",
    "\n",
    "    # patch size in global coords\n",
    "    box_h, box_w = (p_size * cp[2:4] / anchor_crop_size).tolist()\n",
    "\n",
    "    #### 2. COMPUTE EACH ANCHOR'S PATCH POSITION BY SUBTRACTING THE ANCHOR'S GT DISPLACEMENT\n",
    "\n",
    "    gt_dt = io[\"gt_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "    pred_dt = io[\"pred_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "    pred_ds = io[\"pred_dT\"][batch_idx, :, :, 2:] * math.log(model.max_scale_ratio)\n",
    "\n",
    "    # gt_T_global and gt_S_global are the global positions and scales for all patches\n",
    "    gt_T_global = gt_dt[:, 0] + anchor_global_pos\n",
    "    gt_S_global = gt_ds[:, 0] + anchor_global_scale\n",
    "    # pred_T_global and pred_S_global are the predicted means of the global positions and scales for all patches\n",
    "    pred_T_global = pred_dt[:, 0] + anchor_global_pos\n",
    "    pred_S_global = pred_ds[:, 0] + anchor_global_scale\n",
    "\n",
    "    py_tl = anchor_tl[0].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 0] * canon_size\n",
    "    px_tl = anchor_tl[1].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 1] * canon_size\n",
    "\n",
    "\n",
    "\n",
    "    # predicted dispersion for heatmap\n",
    "    # disp = io['disp_dT'][batch_idx, anchor_idx, :, :2]  # [N,2]\n",
    "    # b_norm_y, b_norm_x = disp[patch_idx].cpu().tolist()\n",
    "    # if disp_scale_pixels:\n",
    "    #     b_y = b_norm_y * canon_size\n",
    "    #     b_x = b_norm_x * canon_size\n",
    "    # else:\n",
    "    #     b_y, b_x = b_norm_y, b_norm_x\n",
    "\n",
    "    # predicted mean offset for this patch\n",
    "    pred_off = io['pred_dT'][batch_idx, anchor_idx, patch_idx, :2] * canon_size\n",
    "    mu_y = (anchor_tl[0] - pred_off[0]).item()\n",
    "    mu_x = (anchor_tl[1] - pred_off[1]).item()\n",
    "\n",
    "    # reconstruct canonical image\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # build heatmap at predicted mean\n",
    "    ys = np.arange(H)[:,None]\n",
    "    xs = np.arange(W)[None,:]\n",
    "    Z = (1.0/(4*b_y*b_x)) * np.exp(-np.abs(ys-mu_y)/b_y - np.abs(xs-mu_x)/b_x)\n",
    "    # Z = Z / Z.max()\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(canon, interpolation='nearest')\n",
    "\n",
    "    # draw GT box for anchor (blue) at its top-left, with position in label\n",
    "    rect_a = Rectangle(\n",
    "        (ax_tl, ay_tl), box_w, box_h,\n",
    "        edgecolor='blue', lw=2, facecolor='none',\n",
    "        label=f'Anchor GT (TL): ({ay_tl:.1f}, {ax_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_a)\n",
    "\n",
    "    # draw GT box for target patch (red) at its top-left, with position\n",
    "    rect_p = Rectangle(\n",
    "        (px_tl, py_tl), box_w, box_h,\n",
    "        edgecolor='red', lw=2, facecolor='none',\n",
    "        label=f'Patch GT (TL): ({py_tl:.1f}, {px_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_p)\n",
    "\n",
    "    # legend and title\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(\n",
    "        f'anchor={anchor_idx} → patch={patch_idx}   '\\\n",
    "        f'Pred mean=(%.1f,%.1f)' % (mu_y, mu_x)\n",
    "    )\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_patch_distribution(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    patch_idx=16,\n",
    "    # patch_idx=16,\n",
    "    figsize=(6, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  ANIMATION ACROSS (anchor_idx, patch_idx) PAIRS\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def animate_all_pairs(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx: int = 0,\n",
    "    anchors: list | None = None,\n",
    "    patch_order: str = 'sequential',  # or 'random'\n",
    "    fps: int = 2,\n",
    "    disp_scale_pixels: bool = True,\n",
    "    figsize=(6,6),\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a matplotlib.animation that iterates over every (anchor, patch) pair.\n",
    "\n",
    "    Args:\n",
    "        anchors: list of anchor indices to iterate. If None, uses all patches.\n",
    "        patch_order: 'sequential' or 'random' iteration of target patches.\n",
    "        fps: frames per second for the resulting animation.\n",
    "\n",
    "    Returns:\n",
    "        anim (FuncAnimation) – you can save with anim.save('out.mp4', fps=fps)\n",
    "    \"\"\"\n",
    "    if anchors is None:\n",
    "        anchors = list(range(io['pred_dT'].shape[2]))\n",
    "\n",
    "    # prepare list of (anchor_idx, patch_idx)\n",
    "    pairs = []\n",
    "    for a in anchors:\n",
    "        patches = list(range(io['pred_dT'].shape[2]))\n",
    "        if patch_order == 'random':\n",
    "            np.random.shuffle(patches)\n",
    "        for p in patches:\n",
    "            pairs.append((a, p))\n",
    "\n",
    "    # set up matplotlib figure once\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "\n",
    "    def init():\n",
    "        ax.clear()\n",
    "        ax.axis('off')\n",
    "        return []\n",
    "\n",
    "    def update(frame_idx):\n",
    "        a_idx, p_idx = pairs[frame_idx]\n",
    "        ax.clear()\n",
    "        ax.axis('off')\n",
    "        # generate the frame using the static function\n",
    "        frame_fig = visualize_patch_distribution(\n",
    "            io, model, train_transform, img,\n",
    "            batch_idx=batch_idx,\n",
    "            anchor_idx=a_idx,\n",
    "            patch_idx=p_idx,\n",
    "            figsize=figsize,\n",
    "            disp_scale_pixels=disp_scale_pixels,\n",
    "        )\n",
    "        # extract the Axes image from the returned fig & draw onto our ax\n",
    "        ax.imshow(frame_fig.axes[0].images[0].get_array(), interpolation='nearest')\n",
    "        ax.imshow(frame_fig.axes[0].images[1].get_array(), cmap='hot', alpha=0.5,)\n",
    "        for child in frame_fig.axes[0].get_children():\n",
    "            if isinstance(child, Rectangle):\n",
    "                ax.add_patch(Rectangle(child.get_xy(), child.get_width(), child.get_height(),\n",
    "                                        edgecolor=child.get_edgecolor(), facecolor='none', lw=child.get_lw()))\n",
    "        ax.set_title(f'anchor={a_idx} → patch={p_idx}')\n",
    "        plt.close(frame_fig)\n",
    "        return ax.patches  # need to return updated artists\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update,\n",
    "        init_func=init,\n",
    "        frames=len(pairs),\n",
    "        interval=1000//fps,\n",
    "        blit=False,\n",
    "        repeat=True,\n",
    "    )\n",
    "    return anim\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Example usage (inside a notebook):\n",
    "# anim = animate_all_pairs(io, model, train_transform, img, batch_idx=0, fps=2, anchors=[0])\n",
    "# from IPython.display import HTML\n",
    "# HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anim = animate_all_pairs(io, model, train_transform, img, batch_idx=0, fps=2, anchors=[0])\n",
    "# anim.save(\"uncertainty.mp4\", fps=2, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cluster_and_plot_patches(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_unc=0.05,\n",
    "    eps=0.1,\n",
    "    min_samples=5,\n",
    "    figsize=(8,8),\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Extract (mu_x, mu_y, b_x, b_y) for each patch\n",
    "    2) Normalize and cluster with DBSCAN\n",
    "    3) Overlay clusters on the canonical image\n",
    "\n",
    "    Args:\n",
    "        io: dict containing model I/O tensors\n",
    "        model: object with view_ids_M, Is, canonical_img_size, patch_size\n",
    "        train_transform: must have recreate_canonical(img, params)\n",
    "        img: input image batch element\n",
    "        batch_idx: which batch to use\n",
    "        anchor_idx: which patch to anchor on\n",
    "        sigma_unc: scale for uncertainty normalization\n",
    "        eps, min_samples: DBSCAN tuning\n",
    "        figsize: plot size\n",
    "    \"\"\"\n",
    "    # canonical image size\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # determine anchor's crop view\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local patch pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size  # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]               # [N,2]\n",
    "\n",
    "    # reconstruct canonical image and get dims\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # compute predicted centers\n",
    "    # note: subtract offsets per your GT convention\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt        # [N,2] tensor\n",
    "    bs  = disp                                    # [N,2]\n",
    "\n",
    "    # to numpy\n",
    "    mus_np = mus.cpu().numpy()\n",
    "    bs_np  = bs.cpu().numpy()\n",
    "\n",
    "    # mask points inside image\n",
    "    y, x = mus_np[:,0], mus_np[:,1]\n",
    "    in_bounds = (y >= 0) & (y <= H) & (x >= 0) & (x <= W)\n",
    "    mus_np = mus_np[in_bounds]\n",
    "    bs_np  = bs_np[in_bounds]\n",
    "\n",
    "    # build features\n",
    "    mus_norm = mus_np / canon_size\n",
    "    bs_norm  = bs_np  / (canon_size * sigma_unc)\n",
    "    features = np.hstack([mus_norm, bs_norm])     # [M,4]\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
    "    labels = db.labels_                           # length M\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    scatter = plt.scatter(\n",
    "        mus_np[:,1], mus_np[:,0],\n",
    "        c=labels, cmap='tab20', s=40, edgecolor='k'\n",
    "    )\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    plt.title(f'DBSCAN Clustering: {n_clusters} clusters (σ_unc={sigma_unc}, eps={eps})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return labels, features\n",
    "\n",
    "# Example usage:\n",
    "labels, features = cluster_and_plot_patches(io, model, train_transform, img,\n",
    "                                  batch_idx=0, anchor_idx=0,\n",
    "                                  sigma_unc=0.5, eps=0.06, min_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Helper to plot k-distance graph for eps tuning\n",
    "def plot_k_distance(features, k=5):\n",
    "    \"\"\"\n",
    "    Plot the sorted k-distance graph (distance to k-th nearest neighbor) to help choose eps.\n",
    "\n",
    "    Args:\n",
    "        features: numpy array of shape [N, D]\n",
    "        k: number of neighbors\n",
    "    \"\"\"\n",
    "    # Compute k-nearest distances\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(features)\n",
    "    distances, _ = nbrs.kneighbors(features)\n",
    "    # distances[:,0] is zero (self), so take distances[:,k]\n",
    "    k_distances = np.sort(distances[:, k])\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(k_distances)\n",
    "    plt.xlabel(f'Samples sorted by distance to {k}th NN')\n",
    "    plt.ylabel(f'{k}th NN distance')\n",
    "    plt.title('k-distance graph for DBSCAN eps selection')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage in your notebook:\n",
    "plot_k_distance(features, k=5)\n",
    "\n",
    "# After inspecting the elbow point on the graph, pick eps where the curve shows a knee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cluster_and_plot_patches(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_unc=0.05,\n",
    "    eps=0.1,\n",
    "    min_samples=5,\n",
    "    figsize=(8,8),\n",
    "    tune_sigma: bool = False,\n",
    "    sigma_range=(0.01, 0.2, 10),\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Extract (mu_x, mu_y, b_x, b_y) for each patch\n",
    "    2) Normalize and cluster with DBSCAN\n",
    "    3) Overlay clusters on the canonical image\n",
    "\n",
    "    Args:\n",
    "        io: dict containing model I/O tensors\n",
    "        model: object with view_ids_M, Is, canonical_img_size, patch_size\n",
    "        train_transform: must have recreate_canonical(img, params)\n",
    "        img: input image batch element\n",
    "        batch_idx: which batch to use\n",
    "        anchor_idx: which patch to anchor on\n",
    "        sigma_unc: scale for uncertainty normalization\n",
    "        eps, min_samples: DBSCAN tuning\n",
    "        figsize: plot size\n",
    "    \"\"\"\n",
    "    # canonical image size\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # determine anchor's crop view\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local patch pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size  # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]               # [N,2]\n",
    "\n",
    "    # reconstruct canonical image and get dims\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # compute predicted centers\n",
    "    # note: subtract offsets per your GT convention\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt        # [N,2] tensor\n",
    "    bs  = disp                                    # [N,2]\n",
    "\n",
    "    # to numpy\n",
    "    mus_np = mus.cpu().numpy()\n",
    "    bs_np  = bs.cpu().numpy()\n",
    "\n",
    "    # mask points inside image\n",
    "    y, x = mus_np[:,0], mus_np[:,1]\n",
    "    in_bounds = (y >= 0) & (y <= H) & (x >= 0) & (x <= W)\n",
    "    mus_np = mus_np[in_bounds]\n",
    "    bs_np  = bs_np[in_bounds]\n",
    "\n",
    "    # build features\n",
    "    mus_norm = mus_np / canon_size\n",
    "    bs_norm  = bs_np  / (canon_size * sigma_unc)\n",
    "    features = np.hstack([mus_norm, bs_norm])     # [M,4]\n",
    "\n",
    "        # optionally plot sigma_unc sensitivity (tune_sigma)\n",
    "    if tune_sigma:\n",
    "        sigmas = np.linspace(*sigma_range)\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        for i, s in enumerate(sigmas, 1):\n",
    "            bs_n = bs_np / (canon_size * s)\n",
    "            feat = np.hstack([mus_norm, bs_n])\n",
    "            # k-distance curve (6th NN)\n",
    "            from sklearn.neighbors import NearestNeighbors\n",
    "            nbrs = NearestNeighbors(n_neighbors=6).fit(feat)\n",
    "            dists, _ = nbrs.kneighbors(feat)\n",
    "            kdist = np.sort(dists[:,5])\n",
    "            ax = plt.subplot(1, len(sigmas), i)\n",
    "            ax.plot(kdist)\n",
    "            ax.set_title(f'sigma_unc={s:.3f}')\n",
    "            ax.set_xlabel('Sample index')\n",
    "            ax.set_ylabel('6th NN distance')\n",
    "        plt.suptitle('k-distance vs. sigma_unc')\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
    "    labels = db.labels_                           # length M\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    scatter = plt.scatter(\n",
    "        mus_np[:,1], mus_np[:,0],\n",
    "        c=labels, cmap='tab20', s=40, edgecolor='k'\n",
    "    )\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    plt.title(f'DBSCAN Clustering: {n_clusters} clusters (σ_unc={sigma_unc}, eps={eps})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return labels\n",
    "\n",
    "labels = cluster_and_plot_patches(\n",
    "    io, model, train_transform, img,\n",
    "    tune_sigma=True,\n",
    "    sigma_range=(0.01, 0.2, 5),  # try 5 values between 0.01 and 0.2\n",
    "    eps=0.06, min_samples=5, sigma_unc=0.001\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def graph_cluster_and_plot(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_pos=0.05,\n",
    "    sigma_unc=0.05,\n",
    "    weight_threshold=0.01,\n",
    "    figsize=(8,8)\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Compute predicted patch centers (mu) and dispersions (b) from anchor -> each patch\n",
    "    2) Build a weighted graph where nodes are patches and edges weighted by\n",
    "       exp(-||mu_i-mu_j||^2 / sigma_pos^2) * exp(-||b_i-b_j||^2 / sigma_unc^2)\n",
    "    3) Prune edges below weight_threshold\n",
    "    4) Run Louvain community detection\n",
    "    5) Plot patches color-coded by community on canonical image\n",
    "\n",
    "    Returns:\n",
    "        partition: dict mapping patch index -> community label\n",
    "    \"\"\"\n",
    "    # canonical size and patch scale\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # anchor view and crop size\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]        # tensor[2]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size   # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]                 # [N,2]\n",
    "\n",
    "    # compute predicted patch centers mu = anchor_tl - pred_dt\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt      # [N,2]\n",
    "    bs  = disp                                 # [N,2]\n",
    "\n",
    "    # to numpy arrays\n",
    "    mus_np = mus.cpu().numpy()  # (N,2)\n",
    "    bs_np  = bs.cpu().numpy()   # (N,2)\n",
    "    N = mus_np.shape[0]\n",
    "\n",
    "    # reconstruct canonical image\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # build weighted graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(N))\n",
    "\n",
    "    # precompute squared norms\n",
    "    mu_sq = np.sum(mus_np**2, axis=1, keepdims=True)\n",
    "    b_sq  = np.sum(bs_np**2, axis=1, keepdims=True)\n",
    "\n",
    "    # pairwise differences\n",
    "    # compute weight matrix efficiently\n",
    "    diff_mu = mus_np[:,None,:] - mus_np[None,:,:]       # [N,N,2]\n",
    "    diff_b  = bs_np[:,None,:] - bs_np[None,:,:]          # [N,N,2]\n",
    "    dist_mu2 = np.sum(diff_mu**2, axis=2)                # [N,N]\n",
    "    dist_b2  = np.sum(diff_b**2, axis=2)\n",
    "\n",
    "    # affinity\n",
    "    W = np.exp(-dist_mu2 / (sigma_pos**2 * canon_size**2)) * \\\n",
    "        np.exp(-dist_b2  / (sigma_unc**2  * canon_size**2))\n",
    "\n",
    "    # add edges above threshold\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            w = W[i,j]\n",
    "            if w >= weight_threshold:\n",
    "                G.add_edge(i, j, weight=w)\n",
    "\n",
    "    # Louvain community detection\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    # scatter with community colors\n",
    "    labels = [partition[i] for i in range(N)]\n",
    "    y = mus_np[:,0]\n",
    "    x = mus_np[:,1]\n",
    "    scatter = plt.scatter(\n",
    "        x, y,\n",
    "        c=labels,\n",
    "        cmap='tab20',\n",
    "        s=40,\n",
    "        edgecolor='k'\n",
    "    )\n",
    "    # title\n",
    "    num_com = len(set(labels))\n",
    "    plt.title(f'Louvain Clustering: {num_com} communities')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return partition\n",
    "\n",
    "# Example usage:\n",
    "partition = graph_cluster_and_plot(\n",
    "    io, model, train_transform, img,\n",
    "    batch_idx=0, anchor_idx=34,\n",
    "    sigma_pos=0.7, sigma_unc=1,\n",
    "    weight_threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Literal\n",
    "\n",
    "def create_global_uncertainty_heatmap(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create a global uncertainty heatmap by taking the norm of position dispersions.\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Predicted dispersions for each patch [M, 4] (in pixel units)\n",
    "        canonical_size: Size of the canonical image\n",
    "        patch_size: Size of the patches in the image\n",
    "        \n",
    "    Returns:\n",
    "        uncertainty_map: Global uncertainty heatmap\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    uncertainty_map = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Take norm of position dispersions (dy, dx)\n",
    "    pos_uncertainty = torch.norm(dispersions[:, :2], dim=1)  # [M]\n",
    "    \n",
    "    for i, (pos, unc) in enumerate(zip(patch_positions, pos_uncertainty)):\n",
    "        y, x = pos.int()\n",
    "        # Clamp to image bounds\n",
    "        y = torch.clamp(y, 0, canonical_size - patch_size)\n",
    "        x = torch.clamp(x, 0, canonical_size - patch_size)\n",
    "        \n",
    "        # Add uncertainty to the patch region\n",
    "        uncertainty_map[y:y+patch_size, x:x+patch_size] += unc\n",
    "        \n",
    "    return uncertainty_map\n",
    "\n",
    "\n",
    "def create_laplace_distribution_heatmaps(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    "    alpha: float = 0.7,\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create overlaid Laplace distribution heatmaps at each predicted patch position.\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Per-patch dispersions [M, 4] (in pixel units)\n",
    "        canonical_size: Size of canonical image\n",
    "        patch_size: Size of patches\n",
    "        alpha: Blending factor for overlapping distributions\n",
    "        \n",
    "    Returns:\n",
    "        combined_heatmap: Combined Laplace distributions heatmap\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    combined_heatmap = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    y_coords = torch.arange(canonical_size, device=device).float()\n",
    "    x_coords = torch.arange(canonical_size, device=device).float()\n",
    "    Y, X = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "    \n",
    "    for pos, disp in zip(patch_positions, dispersions):\n",
    "        mu_y, mu_x = pos[0], pos[1]\n",
    "        b_y, b_x = disp[0], disp[1]  # Laplace scale parameters (already in pixel units)\n",
    "        \n",
    "        # Ensure reasonable scale parameters (avoid too small/large values)\n",
    "        b_y = torch.clamp(b_y, min=0.5, max=canonical_size/2)\n",
    "        b_x = torch.clamp(b_x, min=0.5, max=canonical_size/2)\n",
    "        \n",
    "        # Only compute distribution if patch is reasonably within extended bounds\n",
    "        if (mu_y >= -2*patch_size and mu_y <= canonical_size + 2*patch_size and \n",
    "            mu_x >= -2*patch_size and mu_x <= canonical_size + 2*patch_size):\n",
    "            \n",
    "            # Compute Laplace distribution: (1/(4*b_y*b_x)) * exp(-|y-mu_y|/b_y - |x-mu_x|/b_x)\n",
    "            laplace_dist = (1.0 / (4 * b_y * b_x)) * torch.exp(\n",
    "                -torch.abs(Y - mu_y) / b_y - torch.abs(X - mu_x) / b_x\n",
    "            )\n",
    "            \n",
    "            # Normalize to [0,1] to prevent any single distribution from dominating\n",
    "            if laplace_dist.max() > 0:\n",
    "                laplace_dist = laplace_dist / laplace_dist.max()\n",
    "            \n",
    "            # Add to combined heatmap with additive blending\n",
    "            combined_heatmap += alpha * laplace_dist\n",
    "    \n",
    "    # Normalize the final combined heatmap\n",
    "    if combined_heatmap.max() > 0:\n",
    "        combined_heatmap = combined_heatmap / combined_heatmap.max()\n",
    "    \n",
    "    return combined_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cluster_and_plot_patches(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_unc=0.05,\n",
    "    eps=0.1,\n",
    "    min_samples=5,\n",
    "    figsize=(8,8),\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Extract (mu_x, mu_y, b_x, b_y) for each patch\n",
    "    2) Normalize and cluster with DBSCAN\n",
    "    3) Overlay clusters on the canonical image\n",
    "\n",
    "    Args:\n",
    "        io: dict containing model I/O tensors\n",
    "        model: object with view_ids_M, Is, canonical_img_size, patch_size\n",
    "        train_transform: must have recreate_canonical(img, params)\n",
    "        img: input image batch element\n",
    "        batch_idx: which batch to use\n",
    "        anchor_idx: which patch to anchor on\n",
    "        sigma_unc: scale for uncertainty normalization\n",
    "        eps, min_samples: DBSCAN tuning\n",
    "        figsize: plot size\n",
    "    \"\"\"\n",
    "    # canonical image size\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # determine anchor's crop view\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local patch pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size  # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]               # [N,2]\n",
    "\n",
    "    # reconstruct canonical image and get dims\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # compute predicted centers\n",
    "    # note: subtract offsets per your GT convention\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt        # [N,2] tensor\n",
    "    bs  = disp                                    # [N,2]\n",
    "\n",
    "    # to numpy\n",
    "    mus_np = mus.cpu().numpy()\n",
    "    bs_np  = bs.cpu().numpy()\n",
    "\n",
    "    # mask points inside image\n",
    "    y, x = mus_np[:,0], mus_np[:,1]\n",
    "    in_bounds = (y >= 0) & (y <= H) & (x >= 0) & (x <= W)\n",
    "    mus_np = mus_np[in_bounds]\n",
    "    bs_np  = bs_np[in_bounds]\n",
    "\n",
    "    # build features\n",
    "    mus_norm = mus_np / canon_size\n",
    "    bs_norm  = bs_np  / (canon_size * sigma_unc)\n",
    "    features = np.hstack([mus_norm, bs_norm])     # [M,4]\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
    "    labels = db.labels_                           # length M\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    scatter = plt.scatter(\n",
    "        mus_np[:,1], mus_np[:,0],\n",
    "        c=labels, cmap='tab20', s=40, edgecolor='k'\n",
    "    )\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    plt.title(f'DBSCAN Clustering: {n_clusters} clusters (σ_unc={sigma_unc}, eps={eps})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Example usage:\n",
    "labels, features = cluster_and_plot_patches(io, model, train_transform, img,\n",
    "                                  batch_idx=0, anchor_idx=0,\n",
    "                                  sigma_unc=0.5, eps=0.06, min_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Helper to plot k-distance graph for eps tuning\n",
    "def plot_k_distance(features, k=5):\n",
    "    \"\"\"\n",
    "    Plot the sorted k-distance graph (distance to k-th nearest neighbor) to help choose eps.\n",
    "\n",
    "    Args:\n",
    "        features: numpy array of shape [N, D]\n",
    "        k: number of neighbors\n",
    "    \"\"\"\n",
    "    # Compute k-nearest distances\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(features)\n",
    "    distances, _ = nbrs.kneighbors(features)\n",
    "    # distances[:,0] is zero (self), so take distances[:,k]\n",
    "    k_distances = np.sort(distances[:, k])\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(k_distances)\n",
    "    plt.xlabel(f'Samples sorted by distance to {k}th NN')\n",
    "    plt.ylabel(f'{k}th NN distance')\n",
    "    plt.title('k-distance graph for DBSCAN eps selection')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage in your notebook:\n",
    "plot_k_distance(features, k=5)\n",
    "\n",
    "# After inspecting the elbow point on the graph, pick eps where the curve shows a knee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cluster_and_plot_patches(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_unc=0.05,\n",
    "    eps=0.1,\n",
    "    min_samples=5,\n",
    "    figsize=(8,8),\n",
    "    tune_sigma: bool = False,\n",
    "    sigma_range=(0.01, 0.2, 10),\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Extract (mu_x, mu_y, b_x, b_y) for each patch\n",
    "    2) Normalize and cluster with DBSCAN\n",
    "    3) Overlay clusters on the canonical image\n",
    "\n",
    "    Args:\n",
    "        io: dict containing model I/O tensors\n",
    "        model: object with view_ids_M, Is, canonical_img_size, patch_size\n",
    "        train_transform: must have recreate_canonical(img, params)\n",
    "        img: input image batch element\n",
    "        batch_idx: which batch to use\n",
    "        anchor_idx: which patch to anchor on\n",
    "        sigma_unc: scale for uncertainty normalization\n",
    "        eps, min_samples: DBSCAN tuning\n",
    "        figsize: plot size\n",
    "    \"\"\"\n",
    "    # canonical image size\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # determine anchor's crop view\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local patch pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size  # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]               # [N,2]\n",
    "\n",
    "    # reconstruct canonical image and get dims\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # compute predicted centers\n",
    "    # note: subtract offsets per your GT convention\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt        # [N,2] tensor\n",
    "    bs  = disp                                    # [N,2]\n",
    "\n",
    "    # to numpy\n",
    "    mus_np = mus.cpu().numpy()\n",
    "    bs_np  = bs.cpu().numpy()\n",
    "\n",
    "    # mask points inside image\n",
    "    y, x = mus_np[:,0], mus_np[:,1]\n",
    "    in_bounds = (y >= 0) & (y <= H) & (x >= 0) & (x <= W)\n",
    "    mus_np = mus_np[in_bounds]\n",
    "    bs_np  = bs_np[in_bounds]\n",
    "\n",
    "    # build features\n",
    "    mus_norm = mus_np / canon_size\n",
    "    bs_norm  = bs_np  / (canon_size * sigma_unc)\n",
    "    features = np.hstack([mus_norm, bs_norm])     # [M,4]\n",
    "\n",
    "        # optionally plot sigma_unc sensitivity (tune_sigma)\n",
    "    if tune_sigma:\n",
    "        sigmas = np.linspace(*sigma_range)\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        for i, s in enumerate(sigmas, 1):\n",
    "            bs_n = bs_np / (canon_size * s)\n",
    "            feat = np.hstack([mus_norm, bs_n])\n",
    "            # k-distance curve (6th NN)\n",
    "            from sklearn.neighbors import NearestNeighbors\n",
    "            nbrs = NearestNeighbors(n_neighbors=6).fit(feat)\n",
    "            dists, _ = nbrs.kneighbors(feat)\n",
    "            kdist = np.sort(dists[:,5])\n",
    "            ax = plt.subplot(1, len(sigmas), i)\n",
    "            ax.plot(kdist)\n",
    "            ax.set_title(f'sigma_unc={s:.3f}')\n",
    "            ax.set_xlabel('Sample index')\n",
    "            ax.set_ylabel('6th NN distance')\n",
    "        plt.suptitle('k-distance vs. sigma_unc')\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
    "    labels = db.labels_                           # length M\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    scatter = plt.scatter(\n",
    "        mus_np[:,1], mus_np[:,0],\n",
    "        c=labels, cmap='tab20', s=40, edgecolor='k'\n",
    "    )\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    plt.title(f'DBSCAN Clustering: {n_clusters} clusters (σ_unc={sigma_unc}, eps={eps})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return labels\n",
    "\n",
    "labels = cluster_and_plot_patches(\n",
    "    io, model, train_transform, img,\n",
    "    tune_sigma=True,\n",
    "    sigma_range=(0.01, 0.2, 5),  # try 5 values between 0.01 and 0.2\n",
    "    eps=0.06, min_samples=5, sigma_unc=0.001\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def graph_cluster_and_plot(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_pos=0.05,\n",
    "    sigma_unc=0.05,\n",
    "    weight_threshold=0.01,\n",
    "    figsize=(8,8)\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Compute predicted patch centers (mu) and dispersions (b) from anchor -> each patch\n",
    "    2) Build a weighted graph where nodes are patches and edges weighted by\n",
    "       exp(-||mu_i-mu_j||^2 / sigma_pos^2) * exp(-||b_i-b_j||^2 / sigma_unc^2)\n",
    "    3) Prune edges below weight_threshold\n",
    "    4) Run Louvain community detection\n",
    "    5) Plot patches color-coded by community on canonical image\n",
    "\n",
    "    Returns:\n",
    "        partition: dict mapping patch index -> community label\n",
    "    \"\"\"\n",
    "    # canonical size and patch scale\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # anchor view and crop size\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]        # tensor[2]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size   # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]                 # [N,2]\n",
    "\n",
    "    # compute predicted patch centers mu = anchor_tl - pred_dt\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt      # [N,2]\n",
    "    bs  = disp                                 # [N,2]\n",
    "\n",
    "    # to numpy arrays\n",
    "    mus_np = mus.cpu().numpy()  # (N,2)\n",
    "    bs_np  = bs.cpu().numpy()   # (N,2)\n",
    "    N = mus_np.shape[0]\n",
    "\n",
    "    # reconstruct canonical image\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # build weighted graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(N))\n",
    "\n",
    "    # precompute squared norms\n",
    "    mu_sq = np.sum(mus_np**2, axis=1, keepdims=True)\n",
    "    b_sq  = np.sum(bs_np**2, axis=1, keepdims=True)\n",
    "\n",
    "    # pairwise differences\n",
    "    # compute weight matrix efficiently\n",
    "    diff_mu = mus_np[:,None,:] - mus_np[None,:,:]       # [N,N,2]\n",
    "    diff_b  = bs_np[:,None,:] - bs_np[None,:,:]          # [N,N,2]\n",
    "    dist_mu2 = np.sum(diff_mu**2, axis=2)                # [N,N]\n",
    "    dist_b2  = np.sum(diff_b**2, axis=2)\n",
    "\n",
    "    # affinity\n",
    "    W = np.exp(-dist_mu2 / (sigma_pos**2 * canon_size**2)) * \\\n",
    "        np.exp(-dist_b2  / (sigma_unc**2  * canon_size**2))\n",
    "\n",
    "    # add edges above threshold\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            w = W[i,j]\n",
    "            if w >= weight_threshold:\n",
    "                G.add_edge(i, j, weight=w)\n",
    "\n",
    "    # Louvain community detection\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    # scatter with community colors\n",
    "    labels = [partition[i] for i in range(N)]\n",
    "    y = mus_np[:,0]\n",
    "    x = mus_np[:,1]\n",
    "    scatter = plt.scatter(\n",
    "        x, y,\n",
    "        c=labels,\n",
    "        cmap='tab20',\n",
    "        s=40,\n",
    "        edgecolor='k'\n",
    "    )\n",
    "    # title\n",
    "    num_com = len(set(labels))\n",
    "    plt.title(f'Louvain Clustering: {num_com} communities')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return partition\n",
    "\n",
    "# Example usage:\n",
    "partition = graph_cluster_and_plot(\n",
    "    io, model, train_transform, img,\n",
    "    batch_idx=0, anchor_idx=34,\n",
    "    sigma_pos=0.7, sigma_unc=1,\n",
    "    weight_threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Literal\n",
    "\n",
    "def create_global_uncertainty_heatmap(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create a global uncertainty heatmap by taking the norm of position dispersions.\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Predicted dispersions for each patch [M, 4] (in pixel units)\n",
    "        canonical_size: Size of the canonical image\n",
    "        patch_size: Size of the patches in the image\n",
    "        \n",
    "    Returns:\n",
    "        uncertainty_map: Global uncertainty heatmap\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    uncertainty_map = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Take norm of position dispersions (dy, dx)\n",
    "    pos_uncertainty = torch.norm(dispersions[:, :2], dim=1)  # [M]\n",
    "    \n",
    "    for i, (pos, unc) in enumerate(zip(patch_positions, pos_uncertainty)):\n",
    "        y, x = pos.int()\n",
    "        # Clamp to image bounds\n",
    "        y = torch.clamp(y, 0, canonical_size - patch_size)\n",
    "        x = torch.clamp(x, 0, canonical_size - patch_size)\n",
    "        \n",
    "        # Add uncertainty to the patch region\n",
    "        uncertainty_map[y:y+patch_size, x:x+patch_size] += unc\n",
    "        \n",
    "    return uncertainty_map\n",
    "\n",
    "\n",
    "def create_laplace_distribution_heatmaps(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    "    alpha: float = 0.7,\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create overlaid Laplace distribution heatmaps at each predicted patch position.\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Per-patch dispersions [M, 4] (in pixel units)\n",
    "        canonical_size: Size of canonical image\n",
    "        patch_size: Size of patches\n",
    "        alpha: Blending factor for overlapping distributions\n",
    "        \n",
    "    Returns:\n",
    "        combined_heatmap: Combined Laplace distributions heatmap\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    combined_heatmap = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    y_coords = torch.arange(canonical_size, device=device).float()\n",
    "    x_coords = torch.arange(canonical_size, device=device).float()\n",
    "    Y, X = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "    \n",
    "    for pos, disp in zip(patch_positions, dispersions):\n",
    "        mu_y, mu_x = pos[0], pos[1]\n",
    "        b_y, b_x = disp[0], disp[1]  # Laplace scale parameters (already in pixel units)\n",
    "        \n",
    "        # Ensure reasonable scale parameters (avoid too small/large values)\n",
    "        b_y = torch.clamp(b_y, min=0.5, max=canonical_size/2)\n",
    "        b_x = torch.clamp(b_x, min=0.5, max=canonical_size/2)\n",
    "        \n",
    "        # Only compute distribution if patch is reasonably within extended bounds\n",
    "        if (mu_y >= -2*patch_size and mu_y <= canonical_size + 2*patch_size and \n",
    "            mu_x >= -2*patch_size and mu_x <= canonical_size + 2*patch_size):\n",
    "            \n",
    "            # Compute Laplace distribution: (1/(4*b_y*b_x)) * exp(-|y-mu_y|/b_y - |x-mu_x|/b_x)\n",
    "            laplace_dist = (1.0 / (4 * b_y * b_x)) * torch.exp(\n",
    "                -torch.abs(Y - mu_y) / b_y - torch.abs(X - mu_x) / b_x\n",
    "            )\n",
    "            \n",
    "            # Normalize to [0,1] to prevent any single distribution from dominating\n",
    "            if laplace_dist.max() > 0:\n",
    "                laplace_dist = laplace_dist / laplace_dist.max()\n",
    "            \n",
    "            # Add to combined heatmap with additive blending\n",
    "            combined_heatmap += alpha * laplace_dist\n",
    "    \n",
    "    # Normalize the final combined heatmap\n",
    "    if combined_heatmap.max() > 0:\n",
    "        combined_heatmap = combined_heatmap / combined_heatmap.max()\n",
    "    \n",
    "    return combined_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(io[\"disp_T\"].shape) # [1, 294, 4] # [B, M, 4] # 4 for dy, dx, dlogh, dlogw\n",
    "print(io[\"patch_positions_nopos\"].shape) # [1, 294, 2] # y, x coordinates, where \n",
    "print(io[\"gt_dT\"].shape) # [1, 294, 4] # ground truth displacement\n",
    "# each disp_T is associated with a patch position, where \n",
    "print(io[\"patch_positions_nopos\"].max())\n",
    "print(io[\"params\"])\n",
    "print(io[\"crop_params\"])\n",
    "# the way to get the coordinates of each patch in the canonical image is to first obtain an anchor\n",
    "# that is, let's pick patch 0, obtain its position in the canonical image and then add it to gt_dT\n",
    "\n",
    "\"\"\"\n",
    "dT = pred_dT[..., :2] * canonical_img_size\n",
    "dS = pred_dT[..., 2:] * math.log(max_scale_ratio)\n",
    "\n",
    "\n",
    "# Choose the anchor: first patch of the first global crop (global index 0).\n",
    "T_anchor = (\n",
    "    crop_params[0][:2]\n",
    "    + (patch_positions_nopos[0] / x[0].shape[1]) * crop_params[0][2:4]\n",
    ")\n",
    "S_anchor = torch.log((patch_size * crop_params[0][2:4] / x[0].shape[1]))\n",
    "\n",
    "T_global = dT[:, 0] + T_anchor\n",
    "S_global = dS[:, 0] + S_anchor\n",
    "\"\"\"\n",
    "\n",
    "batch_idx = 0\n",
    "anchor_idx = 0\n",
    "crop_size = io[\"x\"][batch_idx][0].shape[-1]\n",
    "\n",
    "anchor_params = io[\"crop_params\"][batch_idx][anchor_idx]\n",
    "anchor_local_pos = io[\"patch_positions_nopos\"][batch_idx][anchor_idx]\n",
    "anchor_global_pos = anchor_params[:2] + (anchor_local_pos / crop_size) * anchor_params[2:4]\n",
    "anchor_global_scale = torch.log((model.patch_size * anchor_params[2:4] / crop_size))\n",
    "print(\"Anchor global position:\", anchor_global_pos)\n",
    "print(\"Anchor global scale:\", anchor_global_scale)\n",
    "\n",
    "# Calculate global positions and scales for all patches\n",
    "gt_dt = io[\"gt_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "gt_ds = io[\"gt_dT\"][batch_idx, :, :, 2:] * math.log(model.max_scale_ratio)\n",
    "pred_dt = io[\"pred_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "pred_ds = io[\"pred_dT\"][batch_idx, :, :, 2:] * math.log(model.max_scale_ratio)\n",
    "\n",
    "print(io[\"gt_dT\"].shape)  # [1, 294, 294, 4]\n",
    "print(gt_dt.shape)  # [294, 2]\n",
    "print(anchor_global_pos.shape)  # [2]\n",
    "# gt_T_global and gt_S_global are the global positions and scales for all patches\n",
    "gt_T_global = gt_dt[:, 0] + anchor_global_pos\n",
    "gt_S_global = gt_ds[:, 0] + anchor_global_scale\n",
    "# pred_T_global and pred_S_global are the predicted means of the global positions and scales for all patches\n",
    "pred_T_global = pred_dt[:, 0] + anchor_global_pos\n",
    "pred_S_global = pred_ds[:, 0] + anchor_global_scale\n",
    "\n",
    "print(\"Global positions:\", gt_T_global.shape)\n",
    "print(\"Global scales:\", gt_S_global.shape)\n",
    "\n",
    "# cool\n",
    "# now, let's pick an arbitrary patch\n",
    "# and plot a laplacian distribution of the displacements given the mean (pred_dT) and the variance/lap. scale (disp_dT)\n",
    "\n",
    "patch_idx = 0\n",
    "print(io[\"disp_dT\"].shape)  # [1, 294, 294, 4]\n",
    "disp_patch_to_all = io[\"disp_dT\"][batch_idx, patch_idx]\n",
    "# we can only visualize the y and x dispersions\n",
    "disp_patch_to_all = disp_patch_to_all[:, :2]  # [294, 2]\n",
    "\n",
    "print(pred_T_global.shape)\n",
    "mu_patch = pred_T_global[patch_idx]  # [2]\n",
    "\n",
    "# now, we display the canonical image\n",
    "canonical_img = train_transform.recreate_canonical(\n",
    "    img, io[\"canonical_params\"][0]\n",
    ")\n",
    "# and add a bounding box around the chosen patch_idx\n",
    "# and the laplacian distribution given the mean and the variance  (i assume as a heatmap)\n",
    "print(disp_patch_to_all.median())  # [294, 2]\n",
    "print(disp_patch_to_all.quantile(0.75) - disp_patch_to_all.quantile(0.25))  # [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the per-token dispersions.\n",
    "print(io[\"disp_T\"].shape) # (B, V * num_tokens_per_view, 4) # one uncertainty per dimension (y, x, dlogh, dlogw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "def visualize_patch_distribution(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx: int,\n",
    "    anchor_idx: int,\n",
    "    patch_idx: int,\n",
    "    figsize=(6,6),\n",
    "    disp_scale_pixels: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize the predicted 2D Laplacian distribution from anchor -> patch,\n",
    "    drawing ground-truth bounding boxes (top-left) for both anchor and target patches,\n",
    "    and displaying their exact positions in the legend.\n",
    "\n",
    "    Args:\n",
    "        io: dict with keys 'pred_dT','disp_dT','gt_dT','crop_params',\n",
    "            'patch_positions_nopos','canonical_params','x'\n",
    "        model: object with .canonical_img_size, .max_scale_ratio, .patch_size\n",
    "        train_transform: has .recreate_canonical(img, canonical_params)\n",
    "        img: input image for reconstruction\n",
    "        batch_idx: index into batch\n",
    "        anchor_idx: index of anchor patch/crop\n",
    "        patch_idx:  index of target patch\n",
    "        figsize:    matplotlib figure size\n",
    "        disp_scale_pixels: scale predicted dispersion to pixel units\n",
    "    \"\"\"\n",
    "    # sizes\n",
    "    anchor_view_idx = model.view_ids_M[anchor_idx]\n",
    "    anchor_crop_size = model.Is[anchor_view_idx]\n",
    "    canon_size = model.canonical_img_size\n",
    "    p_size = model.patch_size\n",
    "\n",
    "    # retrieve crop params and local positions\n",
    "    cp = io['crop_params'][batch_idx][anchor_view_idx]         # [y0,x0,h',w']\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]  # [y_loc, x_loc]\n",
    "\n",
    "    # anchor base top-left in global coords\n",
    "    anchor_tl = cp[:2] + (lp / anchor_crop_size) * cp[2:4]\n",
    "    ay_tl, ax_tl = anchor_tl.tolist()\n",
    "\n",
    "    # patch size in global coords\n",
    "    box_h, box_w = (p_size * cp[2:4] / anchor_crop_size).tolist()\n",
    "\n",
    "    # current patch TL\n",
    "    # py_tl = tls_y[patch_idx]\n",
    "    # px_tl = tls_x[patch_idx]\n",
    "    py_tl = anchor_tl[0].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 0].item() * canon_size\n",
    "    px_tl = anchor_tl[1].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 1].item() * canon_size\n",
    "\n",
    "    # predicted dispersion for heatmap\n",
    "    disp = io['disp_dT'][batch_idx, anchor_idx, :, :2]  # [N,2]\n",
    "    b_norm_y, b_norm_x = disp[patch_idx].cpu().tolist()\n",
    "    if disp_scale_pixels:\n",
    "        b_y = b_norm_y * canon_size\n",
    "        b_x = b_norm_x * canon_size\n",
    "    else:\n",
    "        b_y, b_x = b_norm_y, b_norm_x\n",
    "\n",
    "    # predicted mean offset for this patch\n",
    "    pred_off = io['pred_dT'][batch_idx, anchor_idx, patch_idx, :2] * canon_size\n",
    "    mu_y = (anchor_tl[0] - pred_off[0]).item()\n",
    "    mu_x = (anchor_tl[1] - pred_off[1]).item()\n",
    "\n",
    "    # reconstruct canonical image\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # build heatmap at predicted mean\n",
    "    ys = np.arange(H)[:,None]\n",
    "    xs = np.arange(W)[None,:]\n",
    "    Z = (1.0/(4*b_y*b_x)) * np.exp(-np.abs(ys-mu_y)/b_y - np.abs(xs-mu_x)/b_x)\n",
    "    # Z = Z / Z.max()\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(canon, interpolation='nearest')\n",
    "\n",
    "    # draw GT box for anchor (blue) at its top-left, with position in label\n",
    "    rect_a = Rectangle(\n",
    "        (ax_tl, ay_tl), box_w, box_h,\n",
    "        edgecolor='blue', lw=2, facecolor='none',\n",
    "        label=f'Anchor GT (TL): ({ay_tl:.1f}, {ax_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_a)\n",
    "\n",
    "    # draw GT box for target patch (red) at its top-left, with position\n",
    "    rect_p = Rectangle(\n",
    "        (px_tl, py_tl), box_w, box_h,\n",
    "        edgecolor='red', lw=2, facecolor='none',\n",
    "        label=f'Patch GT (TL): ({py_tl:.1f}, {px_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_p)\n",
    "\n",
    "    # overlay predicted Laplace heatmap\n",
    "    ax.imshow(Z, cmap='hot', alpha=0.5, extent=(0,W,H,0))\n",
    "\n",
    "    # legend and title\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(\n",
    "        f'anchor={anchor_idx} → patch={patch_idx}   '\\\n",
    "        f'Pred mean=(%.1f,%.1f)' % (mu_y, mu_x)\n",
    "    )\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "def visualize_patch_distribution_per_token(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx: int,\n",
    "    figsize=(6,6),\n",
    "    disp_scale_pixels: bool = True,\n",
    "):\n",
    "    #### 1. COMPUTE AN ANCHOR'S CANONICAL POSITION AND SIZE\n",
    "    # sizes\n",
    "    anchor_idx = 0 # this is just to make the predictions absolute\n",
    "    anchor_view_idx = model.view_ids_M[anchor_idx]\n",
    "    anchor_crop_size = model.Is[anchor_view_idx]\n",
    "    canon_size = model.canonical_img_size\n",
    "    p_size = model.patch_size\n",
    "\n",
    "    # retrieve crop params and local positions\n",
    "    cp = io['crop_params'][batch_idx][anchor_view_idx]         # [y0,x0,h',w']\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]  # [y_loc, x_loc]\n",
    "\n",
    "    # anchor base top-left in global coords\n",
    "    anchor_tl = cp[:2] + (lp / anchor_crop_size) * cp[2:4]\n",
    "    ay_tl, ax_tl = anchor_tl.tolist()\n",
    "\n",
    "    # patch size in global coords\n",
    "    box_h, box_w = (p_size * cp[2:4] / anchor_crop_size).tolist()\n",
    "\n",
    "    #### 2. COMPUTE EACH ANCHOR'S PATCH POSITION BY SUBTRACTING THE ANCHOR'S GT DISPLACEMENT\n",
    "\n",
    "    gt_dt = io[\"gt_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "    pred_dt = io[\"pred_dT\"][batch_idx, :, :, :2] * model.canonical_img_size\n",
    "    pred_ds = io[\"pred_dT\"][batch_idx, :, :, 2:] * math.log(model.max_scale_ratio)\n",
    "\n",
    "    # gt_T_global and gt_S_global are the global positions and scales for all patches\n",
    "    gt_T_global = gt_dt[:, 0] + anchor_global_pos\n",
    "    gt_S_global = gt_ds[:, 0] + anchor_global_scale\n",
    "    # pred_T_global and pred_S_global are the predicted means of the global positions and scales for all patches\n",
    "    pred_T_global = pred_dt[:, 0] + anchor_global_pos\n",
    "    pred_S_global = pred_ds[:, 0] + anchor_global_scale\n",
    "\n",
    "    py_tl = anchor_tl[0].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 0] * canon_size\n",
    "    px_tl = anchor_tl[1].item() - io['gt_dT'][batch_idx, anchor_idx, patch_idx, 1] * canon_size\n",
    "\n",
    "\n",
    "\n",
    "    # predicted dispersion for heatmap\n",
    "    # disp = io['disp_dT'][batch_idx, anchor_idx, :, :2]  # [N,2]\n",
    "    # b_norm_y, b_norm_x = disp[patch_idx].cpu().tolist()\n",
    "    # if disp_scale_pixels:\n",
    "    #     b_y = b_norm_y * canon_size\n",
    "    #     b_x = b_norm_x * canon_size\n",
    "    # else:\n",
    "    #     b_y, b_x = b_norm_y, b_norm_x\n",
    "\n",
    "    # predicted mean offset for this patch\n",
    "    pred_off = io['pred_dT'][batch_idx, anchor_idx, patch_idx, :2] * canon_size\n",
    "    mu_y = (anchor_tl[0] - pred_off[0]).item()\n",
    "    mu_x = (anchor_tl[1] - pred_off[1]).item()\n",
    "\n",
    "    # reconstruct canonical image\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # build heatmap at predicted mean\n",
    "    ys = np.arange(H)[:,None]\n",
    "    xs = np.arange(W)[None,:]\n",
    "    Z = (1.0/(4*b_y*b_x)) * np.exp(-np.abs(ys-mu_y)/b_y - np.abs(xs-mu_x)/b_x)\n",
    "    # Z = Z / Z.max()\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(canon, interpolation='nearest')\n",
    "\n",
    "    # draw GT box for anchor (blue) at its top-left, with position in label\n",
    "    rect_a = Rectangle(\n",
    "        (ax_tl, ay_tl), box_w, box_h,\n",
    "        edgecolor='blue', lw=2, facecolor='none',\n",
    "        label=f'Anchor GT (TL): ({ay_tl:.1f}, {ax_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_a)\n",
    "\n",
    "    # draw GT box for target patch (red) at its top-left, with position\n",
    "    rect_p = Rectangle(\n",
    "        (px_tl, py_tl), box_w, box_h,\n",
    "        edgecolor='red', lw=2, facecolor='none',\n",
    "        label=f'Patch GT (TL): ({py_tl:.1f}, {px_tl:.1f})'\n",
    "    )\n",
    "    ax.add_patch(rect_p)\n",
    "\n",
    "    # legend and title\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(\n",
    "        f'anchor={anchor_idx} → patch={patch_idx}   '\\\n",
    "        f'Pred mean=(%.1f,%.1f)' % (mu_y, mu_x)\n",
    "    )\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_patch_distribution(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    patch_idx=16,\n",
    "    # patch_idx=16,\n",
    "    figsize=(6, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  ANIMATION ACROSS (anchor_idx, patch_idx) PAIRS\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def animate_all_pairs(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx: int = 0,\n",
    "    anchors: list | None = None,\n",
    "    patch_order: str = 'sequential',  # or 'random'\n",
    "    fps: int = 2,\n",
    "    disp_scale_pixels: bool = True,\n",
    "    figsize=(6,6),\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a matplotlib.animation that iterates over every (anchor, patch) pair.\n",
    "\n",
    "    Args:\n",
    "        anchors: list of anchor indices to iterate. If None, uses all patches.\n",
    "        patch_order: 'sequential' or 'random' iteration of target patches.\n",
    "        fps: frames per second for the resulting animation.\n",
    "\n",
    "    Returns:\n",
    "        anim (FuncAnimation) – you can save with anim.save('out.mp4', fps=fps)\n",
    "    \"\"\"\n",
    "    if anchors is None:\n",
    "        anchors = list(range(io['pred_dT'].shape[2]))\n",
    "\n",
    "    # prepare list of (anchor_idx, patch_idx)\n",
    "    pairs = []\n",
    "    for a in anchors:\n",
    "        patches = list(range(io['pred_dT'].shape[2]))\n",
    "        if patch_order == 'random':\n",
    "            np.random.shuffle(patches)\n",
    "        for p in patches:\n",
    "            pairs.append((a, p))\n",
    "\n",
    "    # set up matplotlib figure once\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "\n",
    "    def init():\n",
    "        ax.clear()\n",
    "        ax.axis('off')\n",
    "        return []\n",
    "\n",
    "    def update(frame_idx):\n",
    "        a_idx, p_idx = pairs[frame_idx]\n",
    "        ax.clear()\n",
    "        ax.axis('off')\n",
    "        # generate the frame using the static function\n",
    "        frame_fig = visualize_patch_distribution(\n",
    "            io, model, train_transform, img,\n",
    "            batch_idx=batch_idx,\n",
    "            anchor_idx=a_idx,\n",
    "            patch_idx=p_idx,\n",
    "            figsize=figsize,\n",
    "            disp_scale_pixels=disp_scale_pixels,\n",
    "        )\n",
    "        # extract the Axes image from the returned fig & draw onto our ax\n",
    "        ax.imshow(frame_fig.axes[0].images[0].get_array(), interpolation='nearest')\n",
    "        ax.imshow(frame_fig.axes[0].images[1].get_array(), cmap='hot', alpha=0.5,)\n",
    "        for child in frame_fig.axes[0].get_children():\n",
    "            if isinstance(child, Rectangle):\n",
    "                ax.add_patch(Rectangle(child.get_xy(), child.get_width(), child.get_height(),\n",
    "                                        edgecolor=child.get_edgecolor(), facecolor='none', lw=child.get_lw()))\n",
    "        ax.set_title(f'anchor={a_idx} → patch={p_idx}')\n",
    "        plt.close(frame_fig)\n",
    "        return ax.patches  # need to return updated artists\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update,\n",
    "        init_func=init,\n",
    "        frames=len(pairs),\n",
    "        interval=1000//fps,\n",
    "        blit=False,\n",
    "        repeat=True,\n",
    "    )\n",
    "    return anim\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Example usage (inside a notebook):\n",
    "# anim = animate_all_pairs(io, model, train_transform, img, batch_idx=0, fps=2, anchors=[0])\n",
    "# from IPython.display import HTML\n",
    "# HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anim = animate_all_pairs(io, model, train_transform, img, batch_idx=0, fps=2, anchors=[0])\n",
    "# anim.save(\"uncertainty.mp4\", fps=2, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cluster_and_plot_patches(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_unc=0.05,\n",
    "    eps=0.1,\n",
    "    min_samples=5,\n",
    "    figsize=(8,8),\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Extract (mu_x, mu_y, b_x, b_y) for each patch\n",
    "    2) Normalize and cluster with DBSCAN\n",
    "    3) Overlay clusters on the canonical image\n",
    "\n",
    "    Args:\n",
    "        io: dict containing model I/O tensors\n",
    "        model: object with view_ids_M, Is, canonical_img_size, patch_size\n",
    "        train_transform: must have recreate_canonical(img, params)\n",
    "        img: input image batch element\n",
    "        batch_idx: which batch to use\n",
    "        anchor_idx: which patch to anchor on\n",
    "        sigma_unc: scale for uncertainty normalization\n",
    "        eps, min_samples: DBSCAN tuning\n",
    "        figsize: plot size\n",
    "    \"\"\"\n",
    "    # canonical image size\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # determine anchor's crop view\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local patch pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size  # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]               # [N,2]\n",
    "\n",
    "    # reconstruct canonical image and get dims\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # compute predicted centers\n",
    "    # note: subtract offsets per your GT convention\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt        # [N,2] tensor\n",
    "    bs  = disp                                    # [N,2]\n",
    "\n",
    "    # to numpy\n",
    "    mus_np = mus.cpu().numpy()\n",
    "    bs_np  = bs.cpu().numpy()\n",
    "\n",
    "    # mask points inside image\n",
    "    y, x = mus_np[:,0], mus_np[:,1]\n",
    "    in_bounds = (y >= 0) & (y <= H) & (x >= 0) & (x <= W)\n",
    "    mus_np = mus_np[in_bounds]\n",
    "    bs_np  = bs_np[in_bounds]\n",
    "\n",
    "    # build features\n",
    "    mus_norm = mus_np / canon_size\n",
    "    bs_norm  = bs_np  / (canon_size * sigma_unc)\n",
    "    features = np.hstack([mus_norm, bs_norm])     # [M,4]\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
    "    labels = db.labels_                           # length M\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    scatter = plt.scatter(\n",
    "        mus_np[:,1], mus_np[:,0],\n",
    "        c=labels, cmap='tab20', s=40, edgecolor='k'\n",
    "    )\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    plt.title(f'DBSCAN Clustering: {n_clusters} clusters (σ_unc={sigma_unc}, eps={eps})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return labels, features\n",
    "\n",
    "# Example usage:\n",
    "labels, features = cluster_and_plot_patches(io, model, train_transform, img,\n",
    "                                  batch_idx=0, anchor_idx=0,\n",
    "                                  sigma_unc=0.5, eps=0.06, min_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Helper to plot k-distance graph for eps tuning\n",
    "def plot_k_distance(features, k=5):\n",
    "    \"\"\"\n",
    "    Plot the sorted k-distance graph (distance to k-th nearest neighbor) to help choose eps.\n",
    "\n",
    "    Args:\n",
    "        features: numpy array of shape [N, D]\n",
    "        k: number of neighbors\n",
    "    \"\"\"\n",
    "    # Compute k-nearest distances\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(features)\n",
    "    distances, _ = nbrs.kneighbors(features)\n",
    "    # distances[:,0] is zero (self), so take distances[:,k]\n",
    "    k_distances = np.sort(distances[:, k])\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(k_distances)\n",
    "    plt.xlabel(f'Samples sorted by distance to {k}th NN')\n",
    "    plt.ylabel(f'{k}th NN distance')\n",
    "    plt.title('k-distance graph for DBSCAN eps selection')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage in your notebook:\n",
    "plot_k_distance(features, k=5)\n",
    "\n",
    "# After inspecting the elbow point on the graph, pick eps where the curve shows a knee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cluster_and_plot_patches(\n",
    "    io,\n",
    "    model,\n",
    "    train_transform,\n",
    "    img,\n",
    "    batch_idx=0,\n",
    "    anchor_idx=0,\n",
    "    sigma_unc=0.05,\n",
    "    eps=0.1,\n",
    "    min_samples=5,\n",
    "    figsize=(8,8),\n",
    "    tune_sigma: bool = False,\n",
    "    sigma_range=(0.01, 0.2, 10),\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Extract (mu_x, mu_y, b_x, b_y) for each patch\n",
    "    2) Normalize and cluster with DBSCAN\n",
    "    3) Overlay clusters on the canonical image\n",
    "\n",
    "    Args:\n",
    "        io: dict containing model I/O tensors\n",
    "        model: object with view_ids_M, Is, canonical_img_size, patch_size\n",
    "        train_transform: must have recreate_canonical(img, params)\n",
    "        img: input image batch element\n",
    "        batch_idx: which batch to use\n",
    "        anchor_idx: which patch to anchor on\n",
    "        sigma_unc: scale for uncertainty normalization\n",
    "        eps, min_samples: DBSCAN tuning\n",
    "        figsize: plot size\n",
    "    \"\"\"\n",
    "    # canonical image size\n",
    "    canon_size = model.canonical_img_size\n",
    "\n",
    "    # determine anchor's crop view\n",
    "    view_idx = model.view_ids_M[anchor_idx]\n",
    "    crop_size = model.Is[view_idx]\n",
    "\n",
    "    # get crop params and local patch pos\n",
    "    cp = io['crop_params'][batch_idx][view_idx]\n",
    "    lp = io['patch_positions_nopos'][batch_idx][anchor_idx]\n",
    "    # compute anchor top-left in canonical coords\n",
    "    anchor_tl = cp[:2] + (lp / crop_size) * cp[2:4]\n",
    "\n",
    "    # predicted offsets and dispersions\n",
    "    pred_dt = io['pred_dT'][batch_idx, anchor_idx, :, :2] * canon_size  # [N,2]\n",
    "    disp    = io['disp_dT'][batch_idx, anchor_idx, :, :2]               # [N,2]\n",
    "\n",
    "    # reconstruct canonical image and get dims\n",
    "    canon = train_transform.recreate_canonical(img, io['canonical_params'][batch_idx])\n",
    "    if torch.is_tensor(canon):\n",
    "        canon = canon.permute(1,2,0).cpu().numpy()\n",
    "    H, W = canon.size[:2]\n",
    "\n",
    "    # compute predicted centers\n",
    "    # note: subtract offsets per your GT convention\n",
    "    mus = anchor_tl.unsqueeze(0) - pred_dt        # [N,2] tensor\n",
    "    bs  = disp                                    # [N,2]\n",
    "\n",
    "    # to numpy\n",
    "    mus_np = mus.cpu().numpy()\n",
    "    bs_np  = bs.cpu().numpy()\n",
    "\n",
    "    # mask points inside image\n",
    "    y, x = mus_np[:,0], mus_np[:,1]\n",
    "    in_bounds = (y >= 0) & (y <= H) & (x >= 0) & (x <= W)\n",
    "    mus_np = mus_np[in_bounds]\n",
    "    bs_np  = bs_np[in_bounds]\n",
    "\n",
    "    # build features\n",
    "    mus_norm = mus_np / canon_size\n",
    "    bs_norm  = bs_np  / (canon_size * sigma_unc)\n",
    "    features = np.hstack([mus_norm, bs_norm])     # [M,4]\n",
    "\n",
    "        # optionally plot sigma_unc sensitivity (tune_sigma)\n",
    "    if tune_sigma:\n",
    "        sigmas = np.linspace(*sigma_range)\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        for i, s in enumerate(sigmas, 1):\n",
    "            bs_n = bs_np / (canon_size * s)\n",
    "            feat = np.hstack([mus_norm, bs_n])\n",
    "            # k-distance curve (6th NN)\n",
    "            from sklearn.neighbors import NearestNeighbors\n",
    "            nbrs = NearestNeighbors(n_neighbors=6).fit(feat)\n",
    "            dists, _ = nbrs.kneighbors(feat)\n",
    "            kdist = np.sort(dists[:,5])\n",
    "            ax = plt.subplot(1, len(sigmas), i)\n",
    "            ax.plot(kdist)\n",
    "            ax.set_title(f'sigma_unc={s:.3f}')\n",
    "            ax.set_xlabel('Sample index')\n",
    "            ax.set_ylabel('6th NN distance')\n",
    "        plt.suptitle('k-distance vs. sigma_unc')\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
    "    labels = db.labels_                           # length M\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(canon, interpolation='nearest')\n",
    "    scatter = plt.scatter(\n",
    "        mus_np[:,1], mus_np[:,0],\n",
    "        c=labels, cmap='tab20', s=40, edgecolor='k'\n",
    "    )\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    plt.title(f'DBSCAN Clustering: {n_clusters} clusters (σ_unc={sigma_unc}, eps={eps})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return labels\n",
    "\n",
    "labels = cluster_and_plot_patches(\n",
    "    io, model, train_transform, img,\n",
    "    tune_sigma=True,\n",
    "    sigma_range=(0.01, 0.2, 5),  # try 5 values between 0.01 and 0.2\n",
    "    eps=0.06, min_samples=5, sigma_unc=0.001\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(*batch)\n",
    "io = clean_model_io(batch, out, 'cuda')\n",
    "fig, axes = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"global_heatmap\"  # or \"global_heatmap\", \"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test both uncertainty visualization modes\n",
    "fig1, axes1 = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"global_heatmap\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "fig2, axes2 = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"laplace_distributions\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Also check the statistics of the dispersions to understand the scale\n",
    "print(\"Dispersion statistics:\")\n",
    "print(f\"disp_T shape: {io['disp_T'].shape}\")\n",
    "print(f\"disp_T min: {io['disp_T'].min():.6f}\")\n",
    "print(f\"disp_T max: {io['disp_T'].max():.6f}\")\n",
    "print(f\"disp_T mean: {io['disp_T'].mean():.6f}\")\n",
    "print(f\"Position dispersions (first 2 dims) - min: {io['disp_T'][0, :, :2].min():.6f}, max: {io['disp_T'][0, :, :2].max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT = Path(\"../../\")\n",
    "# In[1]:\n",
    "\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch.utils.data import  default_collate\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils._pytree as pytree\n",
    "# from src.utils.visualization.reconstruction_v5_anchor_reparam import reconstruction_lstsq_with_anchor_reparam\n",
    "from src.utils.visualization.reconstruction_v6 import reconstruction_lstsq_with_anchor_reparam\n",
    "from src.utils.visualization.reconstruction_v5_gt import reconstruction_gt\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import itertools\n",
    "from jaxtyping import Float, Int\n",
    "from typing import Literal\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# ## Utils\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "def clean_model_io(batch: tuple, out: dict, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Clean and organize model inputs and outputs for visualization and analysis.\n",
    "    \n",
    "    Args:\n",
    "        batch: A tuple containing model inputs (global images, global params, local images, local params)\n",
    "        out: Model output dictionary\n",
    "        device: Device to move tensors to (default: \"cuda\")\n",
    "        \n",
    "    Returns:\n",
    "        io: Dictionary containing organized model inputs and outputs\n",
    "    \"\"\"\n",
    "    # Initialize output dictionary\n",
    "    io = dict()\n",
    "    \n",
    "    # Extract shapes from model output\n",
    "    io[\"x\"] = [list(itertools.chain.from_iterable(items)) for items in zip(*batch[0])]\n",
    "    io[\"params\"] = [list(itertools.chain.from_iterable(items)) for items in zip(*batch[1])]\n",
    "    io[\"canonical_params\"] = [[param[0:4] for param in batch_params] for batch_params in io[\"params\"]][0]\n",
    "    io[\"crop_params\"] = [[param[4:8] for param in batch_params] for batch_params in io[\"params\"]]\n",
    "    \n",
    "    # Include all output values\n",
    "    io.update({name: out[name] for name in out.keys()})\n",
    "    \n",
    "    # Move all tensors to the specified device\n",
    "    io = pytree.tree_map_only(\n",
    "        Tensor,\n",
    "        lambda t: t.detach().to(device),\n",
    "        io\n",
    "    )\n",
    "    return io\n",
    "\n",
    "\n",
    "def make_plots(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    original_img,\n",
    "):\n",
    "    \n",
    "    gt_reconstruction = reconstruction_gt(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "    )\n",
    "    pred_reconstruction, *_ = reconstruction_lstsq_with_anchor_reparam(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "        max_scale_ratio=model.max_scale_ratio,\n",
    "        pred_dT=io[\"pred_dT\"][0],\n",
    "    )\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    canonical_img = train_transform.recreate_canonical(\n",
    "        original_img, io[\"canonical_params\"][0]\n",
    "    )\n",
    "    axes[0].imshow(canonical_img)\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(gt_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[1].set_title(\"GT Reconstruction\")\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[2].imshow(pred_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[2].set_title(\"Reconstruction\")\n",
    "    axes[2].axis(\"off\")\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "# ## Reconstruction\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# overfit to a few batches\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "if not OmegaConf.has_resolver(\"eval\"):\n",
    "    OmegaConf.register_new_resolver(\"eval\", eval)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# FOLDER = ROOT / Path(\"outputs/2025-06-16/13-23-31\")\n",
    "FOLDER = ROOT / Path(\"outputs/2025-06-22/19-16-53\")\n",
    "cfg = OmegaConf.load(FOLDER / \".hydra/config.yaml\")\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "cfg = OmegaConf.load(FOLDER / \".hydra/config.yaml\")\n",
    "if \"predict_uncertainty\" in cfg[\"model\"]:\n",
    "    predict_uncertainty = cfg[\"model\"].pop(\"predict_uncertainty\")\n",
    "    if predict_uncertainty:\n",
    "        cfg[\"model\"][\"uncertainty_mode\"] = \"additive\"\n",
    "    else:\n",
    "        cfg[\"model\"][\"uncertainty_mode\"] = \"none\"\n",
    "elif \"uncertainty_mode\" in cfg[\"model\"]:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(\"Uncertainty mode not specified in the config.\")\n",
    "print(cfg[\"model\"][\"uncertainty_mode\"])\n",
    "ckpt_path = FOLDER / \"epoch_0199.ckpt\"\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cuda\")\n",
    "state_dict = ckpt[\"model\"]\n",
    "if \"pose_head.mu.weight\" in state_dict:\n",
    "    state_dict[\"pose_head.mu_proj.weight\"] = state_dict.pop(\"pose_head.mu.weight\")\n",
    "if \"pose_head.logvar.weight\" in state_dict:\n",
    "    state_dict[\"pose_head.disp_proj.weight\"] = state_dict.pop(\"pose_head.logvar.weight\")\n",
    "if \"pose_head.logvar.bias\" in state_dict:\n",
    "    state_dict[\"pose_head.disp_proj.bias\"] = state_dict.pop(\"pose_head.logvar.bias\")\n",
    "if \"pose_head.gate_proj.weight\" in state_dict:\n",
    "    if \"gate_dim\" not in cfg[\"model\"]:\n",
    "        cfg[\"model\"][\"gate_dim\"] = state_dict[\"pose_head.gate_proj.weight\"].shape[0]\n",
    "        print(f\"Gate dimension not specified in the config, inferring from state_dict: {cfg['model']['gate_dim']}\")\n",
    "    assert cfg[\"model\"][\"gate_dim\"] == state_dict[\"pose_head.gate_proj.weight\"].shape[0]\n",
    "if \"pose_head.gate_mult\" not in state_dict:\n",
    "    state_dict[\"pose_head.gate_mult\"] = torch.zeros(1)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "V = 2\n",
    "gV = 2\n",
    "lV = V - gV\n",
    "if V == 12:\n",
    "    model = hydra.utils.instantiate(\n",
    "        cfg[\"model\"],\n",
    "        # gate_dim=cfg[\"model\"].get(\"gate_dim\", 16),\n",
    "        _target_=\"src.models.components.partmae_v6.PARTMaskedAutoEncoderViT\",\n",
    "        num_views=V,\n",
    "        # mask_ratio=0,\n",
    "        mask_ratio=0.75,\n",
    "        pos_mask_ratio=0.75,\n",
    "        # sampler='ongrid_canonical'\n",
    "    )\n",
    "elif V == 2:\n",
    "    model = hydra.utils.instantiate(\n",
    "        cfg[\"model\"],\n",
    "        # gate_dim=cfg[\"model\"].get(\"gate_dim\", 16),\n",
    "        _target_=\"src.models.components.partmae_v6.PARTMaskedAutoEncoderViT\",\n",
    "        num_views=V,\n",
    "        mask_ratio=0,\n",
    "        pos_mask_ratio=0.75,\n",
    "        # sampler='ongrid_canonical'\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported number of views: {V}\")\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "print(ckpt[\"global_step\"], ckpt[\"epoch\"])\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "img = Image.open(ROOT / \"artifacts/samoyed.jpg\")\n",
    "# .crop((0, 0, 1000, 1000))\n",
    "train_transform = hydra.utils.instantiate(\n",
    "    cfg[\"data\"][\"transform\"], distort_color=False, n_local_crops=V - gV\n",
    ")\n",
    "batch = default_collate([train_transform(img), train_transform(img), train_transform(img), train_transform(img)])\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(*batch)\n",
    "io = clean_model_io(batch, out, 'cuda')\n",
    "fig, axes = make_plots(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "def create_global_confidence_heatmap(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create a global confidence heatmap using inverse of position dispersions.\n",
    "    Higher values = more confidence (lower uncertainty).\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Predicted dispersions for each patch [M, 4] (in pixel units)\n",
    "        canonical_size: Size of the canonical image\n",
    "        patch_size: Size of the patches in the image\n",
    "        \n",
    "    Returns:\n",
    "        confidence_map: Global confidence heatmap (higher = more confident)\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    confidence_map = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Take norm of position dispersions (dy, dx) and invert for confidence\n",
    "    pos_uncertainty = torch.norm(dispersions[:, :2], dim=1)  # [M]\n",
    "    # Convert uncertainty to confidence: higher uncertainty -> lower confidence\n",
    "    pos_confidence = 1.0 / (1.0 + pos_uncertainty)  # [M]\n",
    "    \n",
    "    for i, (pos, conf) in enumerate(zip(patch_positions, pos_confidence)):\n",
    "        y, x = pos.int()\n",
    "        # Clamp to image bounds\n",
    "        y = torch.clamp(y, 0, canonical_size - patch_size)\n",
    "        x = torch.clamp(x, 0, canonical_size - patch_size)\n",
    "        \n",
    "        # Add confidence to the patch region\n",
    "        confidence_map[y:y+patch_size, x:x+patch_size] += conf\n",
    "        \n",
    "    return confidence_map\n",
    "\n",
    "\n",
    "def create_global_uncertainty_heatmap(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create a global uncertainty heatmap by taking the norm of position dispersions.\n",
    "    Higher values = more uncertainty (lower confidence).\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Predicted dispersions for each patch [M, 4] (in pixel units)\n",
    "        canonical_size: Size of the canonical image\n",
    "        patch_size: Size of the patches in the image\n",
    "        \n",
    "    Returns:\n",
    "        uncertainty_map: Global uncertainty heatmap (higher = more uncertain)\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    uncertainty_map = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Take norm of position dispersions (dy, dx) directly for uncertainty\n",
    "    pos_uncertainty = torch.norm(dispersions[:, :2], dim=1)  # [M]\n",
    "    \n",
    "    for i, (pos, unc) in enumerate(zip(patch_positions, pos_uncertainty)):\n",
    "        y, x = pos.int()\n",
    "        # Clamp to image bounds\n",
    "        y = torch.clamp(y, 0, canonical_size - patch_size)\n",
    "        x = torch.clamp(x, 0, canonical_size - patch_size)\n",
    "        \n",
    "        # Add uncertainty to the patch region\n",
    "        uncertainty_map[y:y+patch_size, x:x+patch_size] += unc\n",
    "        \n",
    "    return uncertainty_map\n",
    "\n",
    "\n",
    "def create_laplace_confidence_heatmaps(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    "    alpha: float = 0.7,\n",
    "    confidence_transform: str = \"inverse_width\",  # \"inverse_width\" or \"peak_height\"\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create overlaid Laplace distribution heatmaps showing confidence.\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Per-patch dispersions [M, 4] (in pixel units)\n",
    "        canonical_size: Size of canonical image\n",
    "        patch_size: Size of patches\n",
    "        alpha: Blending factor for overlapping distributions\n",
    "        confidence_transform: How to convert uncertainty to confidence visualization\n",
    "        \n",
    "    Returns:\n",
    "        combined_heatmap: Combined confidence distributions heatmap\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    combined_heatmap = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    y_coords = torch.arange(canonical_size, device=device).float()\n",
    "    x_coords = torch.arange(canonical_size, device=device).float()\n",
    "    Y, X = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "    \n",
    "    for pos, disp in zip(patch_positions, dispersions):\n",
    "        mu_y, mu_x = pos[0], pos[1]\n",
    "        b_y, b_x = disp[0], disp[1]  # Laplace scale parameters (already in pixel units)\n",
    "        \n",
    "        # Ensure reasonable scale parameters\n",
    "        b_y = torch.clamp(b_y, min=0.5, max=canonical_size/2)\n",
    "        b_x = torch.clamp(b_x, min=0.5, max=canonical_size/2)\n",
    "        \n",
    "        # Only compute distribution if patch is reasonably within extended bounds\n",
    "        if (mu_y >= -2*patch_size and mu_y <= canonical_size + 2*patch_size and \n",
    "            mu_x >= -2*patch_size and mu_x <= canonical_size + 2*patch_size):\n",
    "            \n",
    "            # Compute Laplace distribution\n",
    "            laplace_dist = (1.0 / (4 * b_y * b_x)) * torch.exp(\n",
    "                -torch.abs(Y - mu_y) / b_y - torch.abs(X - mu_x) / b_x\n",
    "            )\n",
    "            \n",
    "            if confidence_transform == \"inverse_width\":\n",
    "                # Scale by inverse of width for confidence: narrower = more confident\n",
    "                width_factor = 1.0 / (b_y * b_x)\n",
    "                confidence_factor = width_factor / (1.0 + width_factor)\n",
    "                laplace_dist = laplace_dist * confidence_factor\n",
    "            \n",
    "            # Normalize to [0,1]\n",
    "            if laplace_dist.max() > 0:\n",
    "                laplace_dist = laplace_dist / laplace_dist.max()\n",
    "            \n",
    "            # Add to combined heatmap\n",
    "            combined_heatmap += alpha * laplace_dist\n",
    "    \n",
    "    # Normalize the final combined heatmap\n",
    "    if combined_heatmap.max() > 0:\n",
    "        combined_heatmap = combined_heatmap / combined_heatmap.max()\n",
    "    \n",
    "    return combined_heatmap\n",
    "\n",
    "\n",
    "def create_laplace_distribution_heatmaps(\n",
    "    patch_positions: Float[Tensor, \"M 2\"],\n",
    "    dispersions: Float[Tensor, \"M 4\"],  # [dy, dx, dlogh, dlogw]\n",
    "    canonical_size: int,\n",
    "    patch_size: int,\n",
    "    alpha: float = 0.7,\n",
    ") -> Float[Tensor, \"canonical_size canonical_size\"]:\n",
    "    \"\"\"\n",
    "    Create overlaid Laplace distribution heatmaps at each predicted patch position.\n",
    "    This shows the raw uncertainty distributions without confidence transformation.\n",
    "    \n",
    "    Args:\n",
    "        patch_positions: Predicted patch positions in canonical space [M, 2]\n",
    "        dispersions: Per-patch dispersions [M, 4] (in pixel units)\n",
    "        canonical_size: Size of canonical image\n",
    "        patch_size: Size of patches\n",
    "        alpha: Blending factor for overlapping distributions\n",
    "        \n",
    "    Returns:\n",
    "        combined_heatmap: Combined Laplace distributions heatmap\n",
    "    \"\"\"\n",
    "    device = patch_positions.device\n",
    "    combined_heatmap = torch.zeros((canonical_size, canonical_size), device=device)\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    y_coords = torch.arange(canonical_size, device=device).float()\n",
    "    x_coords = torch.arange(canonical_size, device=device).float()\n",
    "    Y, X = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "    \n",
    "    for pos, disp in zip(patch_positions, dispersions):\n",
    "        mu_y, mu_x = pos[0], pos[1]\n",
    "        b_y, b_x = disp[0], disp[1]  # Laplace scale parameters (already in pixel units)\n",
    "        \n",
    "        # Ensure reasonable scale parameters\n",
    "        b_y = torch.clamp(b_y, min=0.5, max=canonical_size/2)\n",
    "        b_x = torch.clamp(b_x, min=0.5, max=canonical_size/2)\n",
    "        \n",
    "        # Only compute distribution if patch is reasonably within extended bounds\n",
    "        if (mu_y >= -2*patch_size and mu_y <= canonical_size + 2*patch_size and \n",
    "            mu_x >= -2*patch_size and mu_x <= canonical_size + 2*patch_size):\n",
    "            \n",
    "            # Compute Laplace distribution: (1/(4*b_y*b_x)) * exp(-|y-mu_y|/b_y - |x-mu_x|/b_x)\n",
    "            laplace_dist = (1.0 / (4 * b_y * b_x)) * torch.exp(\n",
    "                -torch.abs(Y - mu_y) / b_y - torch.abs(X - mu_x) / b_x\n",
    "            )\n",
    "            \n",
    "            # Normalize to [0,1] to prevent any single distribution from dominating\n",
    "            if laplace_dist.max() > 0:\n",
    "                laplace_dist = laplace_dist / laplace_dist.max()\n",
    "            \n",
    "            # Add to combined heatmap with additive blending\n",
    "            combined_heatmap += alpha * laplace_dist\n",
    "    \n",
    "    # Normalize the final combined heatmap\n",
    "    if combined_heatmap.max() > 0:\n",
    "        combined_heatmap = combined_heatmap / combined_heatmap.max()\n",
    "    \n",
    "    return combined_heatmap\n",
    "\n",
    "\n",
    "def paste_patch(\n",
    "    crop: Float[Tensor, \"C h w\"],\n",
    "    pos: Float[Tensor, \"2\"],\n",
    "    pos_canonical: Float[Tensor, \"2\"],\n",
    "    patch_size_canonical: Float[Tensor, \"2\"],\n",
    "    canvas: Float[Tensor, \"C H W\"],\n",
    "    count_map: Float[Tensor, \"1 H W\"],\n",
    "    patch_size: int,\n",
    "    canonical_size: int,\n",
    "    disp: Float[Tensor, \"4\"] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract a patch from a crop at pos and paste it onto a canvas at pos_canonical with appropriate rescaling.\n",
    "\n",
    "    Args:\n",
    "        crop: Source image crop of shape [C, h, w]\n",
    "        pos: Patch position in crop coordinates [y, x]\n",
    "        pos_canonical: Target position in canonical coordinates [y, x]\n",
    "        patch_size_canonical: Size of patch in canonical space [height, width]\n",
    "        canvas: Target canvas to paste onto [C, H, W]\n",
    "        count_map: Counter for averaging overlapping patches [1, H, W]\n",
    "        patch_size: Size of patch in crop space\n",
    "        canonical_size: Size of the canonical image\n",
    "        disp: Per token dispersion (as in Laplace scale) for each transformation parameter.\n",
    "\n",
    "        pos ~ Laplace(mu_yx, b_yx) \n",
    "    \"\"\"\n",
    "    crop_h, crop_w = crop.shape[1:3]\n",
    "\n",
    "    # Convert to integer coordinates for the canonical position\n",
    "    y_canonical, x_canonical = int(round(pos_canonical[0].item())), int(\n",
    "        round(pos_canonical[1].item())\n",
    "    )\n",
    "\n",
    "    # Get integer patch size for the canonical space\n",
    "    patch_h_canonical, patch_w_canonical = patch_size_canonical.round().int()\n",
    "\n",
    "    # Ensure the patch fits within the canonical canvas\n",
    "    y_canonical = max(0, min(canonical_size - patch_h_canonical, y_canonical))\n",
    "    x_canonical = max(0, min(canonical_size - patch_w_canonical, x_canonical))\n",
    "\n",
    "    # Get source patch coordinates, ensuring they're within the crop boundaries\n",
    "    y_crop, x_crop = int(round(pos[0].item())), int(round(pos[1].item()))\n",
    "    y_crop = max(0, min(crop_h - patch_size, y_crop))\n",
    "    x_crop = max(0, min(crop_w - patch_size, x_crop))\n",
    "\n",
    "    # Extract the patch from the source crop\n",
    "    patch = crop[\n",
    "        :, y_crop : y_crop + patch_size, x_crop : x_crop + patch_size\n",
    "    ].unsqueeze(0)\n",
    "\n",
    "    # Resize the patch to the canonical size\n",
    "    patch_resized = F.interpolate(\n",
    "        patch,\n",
    "        size=(patch_h_canonical, patch_w_canonical),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).squeeze(0)\n",
    "\n",
    "    # Add the patch to the canvas and update the count map\n",
    "    canvas[\n",
    "        :,\n",
    "        y_canonical : y_canonical + patch_h_canonical,\n",
    "        x_canonical : x_canonical + patch_w_canonical,\n",
    "    ] += patch_resized\n",
    "    count_map[\n",
    "        :,\n",
    "        y_canonical : y_canonical + patch_h_canonical,\n",
    "        x_canonical : x_canonical + patch_w_canonical,\n",
    "    ] += 1\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def reconstruction_with_uncertainty_visualization(\n",
    "    x: list[Float[Tensor, \"C gH gW\"] | Float[Tensor, \"C lH lW\"]],\n",
    "    patch_positions_nopos: Float[Tensor, \"M 2\"],\n",
    "    num_tokens: list[int],\n",
    "    crop_params: list[Float[Tensor, \"4\"]],\n",
    "    patch_size: int,\n",
    "    canonical_img_size: int,\n",
    "    max_scale_ratio: float,\n",
    "    pred_dT: Float[Tensor, \"M M 4\"],\n",
    "    disp_T: Float[Tensor, \"M 4\"],  # NOTE: This contains LOG-dispersions\n",
    "    uncertainty_mode: Literal[\"none\", \"confidence_heatmap\", \"confidence_distributions\", \"uncertainty_heatmap\", \"uncertainty_distributions\"] = \"none\",\n",
    ") -> tuple[\n",
    "    Float[Tensor, \"C canonical_img_size canonical_img_size\"],  # reconstructed image\n",
    "    Float[Tensor, \"canonical_img_size canonical_img_size\"] | None,  # uncertainty/confidence map\n",
    "]:\n",
    "    \"\"\"\n",
    "    Reconstruct image with optional uncertainty/confidence visualization.\n",
    "    \n",
    "    Args:\n",
    "        disp_T: Per-token log-dispersions [M, 4] - NOTE: these are in log-space!\n",
    "        uncertainty_mode: \n",
    "            - \"none\": No visualization\n",
    "            - \"confidence_heatmap\": Global confidence heatmap (bright = confident)\n",
    "            - \"confidence_distributions\": Individual Laplace confidence distributions\n",
    "            - \"uncertainty_heatmap\": Global uncertainty heatmap (bright = uncertain)\n",
    "            - \"uncertainty_distributions\": Individual Laplace uncertainty distributions\n",
    "    \n",
    "    Returns:\n",
    "        reconstructed_img: Reconstructed canonical image\n",
    "        uncertainty_map: Uncertainty/confidence visualization (None if uncertainty_mode=\"none\")\n",
    "    \"\"\"\n",
    "    device = x[0].device\n",
    "    C = x[0].shape[0]\n",
    "\n",
    "    # Undo normalization\n",
    "    dT = pred_dT[..., :2] * canonical_img_size\n",
    "    dS = pred_dT[..., 2:] * math.log(max_scale_ratio)\n",
    "\n",
    "    # Choose anchor\n",
    "    T_anchor = (\n",
    "        crop_params[0][:2]\n",
    "        + (patch_positions_nopos[0] / x[0].shape[1]) * crop_params[0][2:4]\n",
    "    )\n",
    "    S_anchor = torch.log((patch_size * crop_params[0][2:4] / x[0].shape[1]))\n",
    "\n",
    "    T_global = dT[:, 0] + T_anchor\n",
    "    S_global = dS[:, 0] + S_anchor\n",
    "\n",
    "    T_global_grouped = torch.split(T_global, num_tokens)\n",
    "    S_global_grouped = torch.split(S_global, num_tokens)\n",
    "    patch_positions_nopos_grouped = torch.split(patch_positions_nopos, num_tokens)\n",
    "    disp_T_grouped = torch.split(disp_T, num_tokens)\n",
    "\n",
    "    # Reconstruct the canonical image\n",
    "    canvas = torch.zeros((C, canonical_img_size, canonical_img_size), device=device)\n",
    "    count_map = torch.zeros((1, canonical_img_size, canonical_img_size), device=device)\n",
    "\n",
    "    for crop, patch_positions, canonical_pos, log_size, disp in zip(\n",
    "        x,\n",
    "        patch_positions_nopos_grouped,\n",
    "        T_global_grouped,\n",
    "        S_global_grouped,\n",
    "        disp_T_grouped,\n",
    "    ):\n",
    "        N = patch_positions.shape[0]\n",
    "        for i in range(N):\n",
    "            paste_patch(\n",
    "                crop=crop,\n",
    "                pos=patch_positions[i].float(),\n",
    "                pos_canonical=canonical_pos[i],\n",
    "                patch_size_canonical=torch.exp(log_size[i]),\n",
    "                canvas=canvas,\n",
    "                count_map=count_map,\n",
    "                patch_size=patch_size,\n",
    "                canonical_size=canonical_img_size,\n",
    "                disp=disp[i]\n",
    "            )\n",
    "\n",
    "    count_map[count_map == 0] = 1\n",
    "    reconstructed_img = canvas / count_map\n",
    "\n",
    "    # Generate uncertainty/confidence visualization\n",
    "    viz_map = None\n",
    "    if uncertainty_mode != \"none\":\n",
    "        # Convert log-dispersions to actual dispersions and scale to pixel units\n",
    "        actual_dispersions = torch.exp(disp_T)  # Convert from log-space\n",
    "        disp_T_pixels = actual_dispersions.clone()\n",
    "        disp_T_pixels[:, :2] *= canonical_img_size  # dy, dx to pixels\n",
    "        disp_T_pixels[:, 2:] *= math.log(max_scale_ratio)  # log-scale factors\n",
    "        \n",
    "        if uncertainty_mode == \"confidence_heatmap\":\n",
    "            viz_map = create_global_confidence_heatmap(\n",
    "                T_global, disp_T_pixels, canonical_img_size, patch_size\n",
    "            )\n",
    "        elif uncertainty_mode == \"confidence_distributions\":\n",
    "            viz_map = create_laplace_confidence_heatmaps(\n",
    "                T_global, disp_T_pixels, canonical_img_size, patch_size\n",
    "            )\n",
    "        elif uncertainty_mode == \"uncertainty_heatmap\":\n",
    "            viz_map = create_global_uncertainty_heatmap(\n",
    "                T_global, disp_T_pixels, canonical_img_size, patch_size\n",
    "            )\n",
    "        elif uncertainty_mode == \"uncertainty_distributions\":\n",
    "            viz_map = create_laplace_distribution_heatmaps(\n",
    "                T_global, disp_T_pixels, canonical_img_size, patch_size\n",
    "            )\n",
    "\n",
    "    return reconstructed_img, viz_map\n",
    "\n",
    "\n",
    "def plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    original_img,\n",
    "    uncertainty_mode: Literal[\"none\", \"confidence_heatmap\", \"confidence_distributions\", \"uncertainty_heatmap\", \"uncertainty_distributions\"] = \"none\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Updated plotting function that supports uncertainty/confidence visualization.\n",
    "    \"\"\"\n",
    "    # Generate GT reconstruction (unchanged)\n",
    "    gt_reconstruction = reconstruction_gt(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "    )\n",
    "    \n",
    "    # Generate prediction with uncertainty\n",
    "    pred_reconstruction, viz_map = reconstruction_with_uncertainty_visualization(\n",
    "        x=io[\"x\"][0],\n",
    "        patch_positions_nopos=io[\"patch_positions_nopos\"][0],\n",
    "        num_tokens=model._Ms,\n",
    "        crop_params=io[\"crop_params\"][0],\n",
    "        patch_size=model.patch_size,\n",
    "        canonical_img_size=model.canonical_img_size,\n",
    "        max_scale_ratio=model.max_scale_ratio,\n",
    "        pred_dT=io[\"pred_dT\"][0],\n",
    "        disp_T=io[\"disp_T\"][0],\n",
    "        uncertainty_mode=uncertainty_mode,\n",
    "    )\n",
    "    \n",
    "    # Determine number of subplots\n",
    "    n_plots = 4 if uncertainty_mode != \"none\" else 3\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(4*n_plots, 4))\n",
    "    \n",
    "    # Original image\n",
    "    canonical_img = train_transform.recreate_canonical(\n",
    "        original_img, io[\"canonical_params\"][0]\n",
    "    )\n",
    "    axes[0].imshow(canonical_img)\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # GT reconstruction\n",
    "    axes[1].imshow(gt_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[1].set_title(\"GT Reconstruction\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    # Predicted reconstruction\n",
    "    axes[2].imshow(pred_reconstruction.permute(1, 2, 0).cpu())\n",
    "    axes[2].set_title(\"Reconstruction\")\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    # Uncertainty/confidence visualization\n",
    "    if uncertainty_mode != \"none\" and viz_map is not None:\n",
    "        # Choose appropriate colormap and title\n",
    "        if \"confidence\" in uncertainty_mode:\n",
    "            cmap = 'hot'  # bright = confident\n",
    "            title_prefix = \"Confidence\"\n",
    "        else:\n",
    "            cmap = 'hot_r'  # bright = uncertain (inverted hot)\n",
    "            title_prefix = \"Uncertainty\"\n",
    "            \n",
    "        mode_name = uncertainty_mode.split('_')[1]  # \"heatmap\" or \"distributions\"\n",
    "        \n",
    "        im = axes[3].imshow(viz_map.cpu(), cmap=cmap, alpha=0.8)\n",
    "        axes[3].set_title(f\"{title_prefix} ({mode_name})\")\n",
    "        axes[3].axis(\"off\")\n",
    "        plt.colorbar(im, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(*batch)\n",
    "io = clean_model_io(batch, out, 'cuda')\n",
    "fig, axes = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"global_heatmap\"  # or \"global_heatmap\", \"none\"\n",
    ")\n",
    "\n",
    "\n",
    "# Test both confidence and uncertainty visualization modes\n",
    "print(\"Testing confidence heatmap visualization...\")\n",
    "fig1, axes1 = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"confidence_heatmap\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"Testing confidence distributions visualization...\")\n",
    "fig2, axes2 = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"confidence_distributions\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"Testing uncertainty heatmap visualization...\")\n",
    "fig3, axes3 = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"uncertainty_heatmap\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"Testing uncertainty distributions visualization...\")\n",
    "fig4, axes4 = plot_reconstruction_with_uncertainty(\n",
    "    model,\n",
    "    io,\n",
    "    train_transform,\n",
    "    img,\n",
    "    uncertainty_mode=\"uncertainty_distributions\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Also check the statistics of the dispersions to understand the scale\n",
    "print(\"Dispersion statistics:\")\n",
    "print(f\"disp_T shape: {io['disp_T'].shape}\")\n",
    "print(f\"disp_T (log-space) min: {io['disp_T'].min():.6f}\")\n",
    "print(f\"disp_T (log-space) max: {io['disp_T'].max():.6f}\")\n",
    "print(f\"disp_T (log-space) mean: {io['disp_T'].mean():.6f}\")\n",
    "\n",
    "# Convert to actual dispersions for better understanding\n",
    "actual_disp = torch.exp(io['disp_T'])\n",
    "print(f\"Actual dispersions min: {actual_disp.min():.6f}\")\n",
    "print(f\"Actual dispersions max: {actual_disp.max():.6f}\")\n",
    "print(f\"Actual dispersions mean: {actual_disp.mean():.6f}\")\n",
    "print(f\"Position dispersions (normalized) - min: {actual_disp[0, :, :2].min():.6f}, max: {actual_disp[0, :, :2].max():.6f}\")\n",
    "\n",
    "# Show what they become in pixel units\n",
    "pixel_disp = actual_disp.clone()\n",
    "pixel_disp[:, :, :2] *= model.canonical_img_size\n",
    "print(f\"Position dispersions (pixels) - min: {pixel_disp[0, :, :2].min():.1f}, max: {pixel_disp[0, :, :2].max():.1f}\")\n",
    "\n",
    "# Debug: Let's check what patches have high vs low uncertainty\n",
    "print(\"\\nDebugging uncertainty interpretation:\")\n",
    "actual_dispersions = torch.exp(io['disp_T'][0])  # [M, 4] for first batch\n",
    "pos_uncertainties = torch.norm(actual_dispersions[:, :2], dim=1)  # [M]\n",
    "print(f\"Min position uncertainty: {pos_uncertainties.min():.6f}\")\n",
    "print(f\"Max position uncertainty: {pos_uncertainties.max():.6f}\")\n",
    "print(f\"Mean position uncertainty: {pos_uncertainties.mean():.6f}\")\n",
    "\n",
    "# Check if smaller dispersions (more confident) are in the center\n",
    "sorted_indices = torch.argsort(pos_uncertainties)\n",
    "most_confident_patches = sorted_indices[:10]  # 10 most confident (smallest dispersion)\n",
    "least_confident_patches = sorted_indices[-10:]  # 10 least confident (largest dispersion)\n",
    "\n",
    "print(f\"\\nMost confident patch positions (smallest dispersions):\")\n",
    "for i in most_confident_patches:\n",
    "    pos = io['patch_positions_nopos'][0][i]\n",
    "    print(f\"  Patch {i}: pos={pos.cpu().numpy()}, uncertainty={pos_uncertainties[i]:.6f}\")\n",
    "\n",
    "print(f\"\\nLeast confident patch positions (largest dispersions):\")\n",
    "for i in least_confident_patches:\n",
    "    pos = io['patch_positions_nopos'][0][i]\n",
    "    print(f\"  Patch {i}: pos={pos.cpu().numpy()}, uncertainty={pos_uncertainties[i]:.6f}\")\n",
    "\n",
    "# Enhanced debugging to understand what's happening\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED ANALYSIS: Understanding Confidence vs Uncertainty\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "actual_dispersions = torch.exp(io['disp_T'][0])  # [M, 4] for first batch\n",
    "pos_uncertainties = torch.norm(actual_dispersions[:, :2], dim=1)  # [M]\n",
    "pos_confidences = 1.0 / (1.0 + pos_uncertainties)\n",
    "\n",
    "print(f\"Uncertainty range: {pos_uncertainties.min():.6f} to {pos_uncertainties.max():.6f}\")\n",
    "print(f\"Confidence range: {pos_confidences.min():.6f} to {pos_confidences.max():.6f}\")\n",
    "\n",
    "# Analyze patch distribution by location\n",
    "patch_positions = io['patch_positions_nopos'][0]  # [M, 2]\n",
    "crop_height, crop_width = io['x'][0][0].shape[1:3]\n",
    "\n",
    "# Classify patches by their position in the crop\n",
    "center_y, center_x = crop_height // 2, crop_width // 2\n",
    "patch_distances_from_center = torch.norm(patch_positions.float() - torch.tensor([center_y, center_x], device=patch_positions.device), dim=1)\n",
    "\n",
    "# Find patches in different regions\n",
    "center_patches = patch_distances_from_center < crop_height * 0.3\n",
    "edge_patches = patch_distances_from_center > crop_height * 0.7\n",
    "\n",
    "print(f\"\\nCenter patches (distance < 30% of crop): {center_patches.sum()} patches\")\n",
    "if center_patches.sum() > 0:\n",
    "    print(f\"  - Mean uncertainty: {pos_uncertainties[center_patches].mean():.6f}\")\n",
    "    print(f\"  - Mean confidence: {pos_confidences[center_patches].mean():.6f}\")\n",
    "\n",
    "print(f\"\\nEdge patches (distance > 70% of crop): {edge_patches.sum()} patches\")\n",
    "if edge_patches.sum() > 0:\n",
    "    print(f\"  - Mean uncertainty: {pos_uncertainties[edge_patches].mean():.6f}\")\n",
    "    print(f\"  - Mean confidence: {pos_confidences[edge_patches].mean():.6f}\")\n",
    "else:\n",
    "    print(\"  - No patches found in edge region\")\n",
    "\n",
    "# Let's also look at medium distance patches\n",
    "medium_patches = (patch_distances_from_center >= crop_height * 0.3) & (patch_distances_from_center <= crop_height * 0.7)\n",
    "print(f\"\\nMedium distance patches (30%-70% of crop): {medium_patches.sum()} patches\")\n",
    "if medium_patches.sum() > 0:\n",
    "    print(f\"  - Mean uncertainty: {pos_uncertainties[medium_patches].mean():.6f}\")\n",
    "    print(f\"  - Mean confidence: {pos_confidences[medium_patches].mean():.6f}\")\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"- Position dispersions range from {pixel_disp[0, :, :2].min():.1f} to {pixel_disp[0, :, :2].max():.1f} pixels\")\n",
    "print(f\"- Most confident patches have ~{pos_uncertainties.min():.3f} uncertainty (very precise)\")\n",
    "print(f\"- Least confident patches have ~{pos_uncertainties.max():.3f} uncertainty (quite uncertain)\")\n",
    "print(f\"- Center patches are more confident ({pos_confidences[center_patches].mean():.3f}) than overall mean ({pos_confidences.mean():.3f})\")\n",
    "\n",
    "print(f\"\\nVisualization Guide:\")\n",
    "print(f\"- CONFIDENCE maps: Bright center = model is confident about dog/main subject\")\n",
    "print(f\"- UNCERTAINTY maps: Dark center = model is less uncertain about dog/main subject\")\n",
    "print(f\"- This pattern makes perfect sense: clear features → confident predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "part",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
